{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2839481b",
   "metadata": {
    "id": "2839481b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "730c9f55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "730c9f55",
    "outputId": "f8b896f1-83a1-4368-d248-ad2849ea1c1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Series</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Close</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>Trades</th>\n",
       "      <th>Deliverable Volume</th>\n",
       "      <th>%Deliverble</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>INFY</td>\n",
       "      <td>EQ</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>1576.85</td>\n",
       "      <td>1576.85</td>\n",
       "      <td>1559.05</td>\n",
       "      <td>1561.95</td>\n",
       "      <td>1560.40</td>\n",
       "      <td>1565.56</td>\n",
       "      <td>4814317</td>\n",
       "      <td>7.537112e+14</td>\n",
       "      <td>150925.0</td>\n",
       "      <td>2996603.0</td>\n",
       "      <td>0.6224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>INFY</td>\n",
       "      <td>EQ</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1572.05</td>\n",
       "      <td>1591.00</td>\n",
       "      <td>1572.05</td>\n",
       "      <td>1580.00</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>1582.44</td>\n",
       "      <td>6058722</td>\n",
       "      <td>9.587563e+14</td>\n",
       "      <td>167938.0</td>\n",
       "      <td>3226132.0</td>\n",
       "      <td>0.5325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>INFY</td>\n",
       "      <td>EQ</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1561.00</td>\n",
       "      <td>1573.65</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1562.00</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1564.66</td>\n",
       "      <td>5913567</td>\n",
       "      <td>9.252700e+14</td>\n",
       "      <td>197132.0</td>\n",
       "      <td>3844762.0</td>\n",
       "      <td>0.6502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>INFY</td>\n",
       "      <td>EQ</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1572.90</td>\n",
       "      <td>1580.15</td>\n",
       "      <td>1560.60</td>\n",
       "      <td>1569.10</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1570.82</td>\n",
       "      <td>5019178</td>\n",
       "      <td>7.884238e+14</td>\n",
       "      <td>136591.0</td>\n",
       "      <td>3354874.0</td>\n",
       "      <td>0.6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>INFY</td>\n",
       "      <td>EQ</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1572.00</td>\n",
       "      <td>1578.00</td>\n",
       "      <td>1543.00</td>\n",
       "      <td>1574.00</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1565.12</td>\n",
       "      <td>9780240</td>\n",
       "      <td>1.530725e+15</td>\n",
       "      <td>192643.0</td>\n",
       "      <td>5825533.0</td>\n",
       "      <td>0.5956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Symbol Series  Prev Close     Open     High      Low     Last  \\\n",
       "0  2021-07-01   INFY     EQ     1580.80  1576.85  1576.85  1559.05  1561.95   \n",
       "1  2021-06-30   INFY     EQ     1563.05  1572.05  1591.00  1572.05  1580.00   \n",
       "2  2021-06-29   INFY     EQ     1571.80  1561.00  1573.65  1559.20  1562.00   \n",
       "3  2021-06-28   INFY     EQ     1574.20  1572.90  1580.15  1560.60  1569.10   \n",
       "4  2021-06-25   INFY     EQ     1559.20  1572.00  1578.00  1543.00  1574.00   \n",
       "\n",
       "     Close     VWAP   Volume      Turnover    Trades  Deliverable Volume  \\\n",
       "0  1560.40  1565.56  4814317  7.537112e+14  150925.0           2996603.0   \n",
       "1  1580.80  1582.44  6058722  9.587563e+14  167938.0           3226132.0   \n",
       "2  1563.05  1564.66  5913567  9.252700e+14  197132.0           3844762.0   \n",
       "3  1571.80  1570.82  5019178  7.884238e+14  136591.0           3354874.0   \n",
       "4  1574.20  1565.12  9780240  1.530725e+15  192643.0           5825533.0   \n",
       "\n",
       "   %Deliverble  \n",
       "0       0.6224  \n",
       "1       0.5325  \n",
       "2       0.6502  \n",
       "3       0.6684  \n",
       "4       0.5956  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"INFY.csv\")\n",
    "df = df.iloc[::-1]  #reversing rows to get current date first\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6129a7c-8e06-4219-89b4-c8d514fdbe46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6129a7c-8e06-4219-89b4-c8d514fdbe46",
    "outputId": "0d482e73-4877-40a2-f33f-a30ca2d3af73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Symbol', 'Series', 'Prev Close', 'Open', 'High', 'Low', 'Last',\n",
       "       'Close', 'VWAP', 'Volume', 'Turnover', 'Trades', 'Deliverable Volume',\n",
       "       '%Deliverble'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971b0ab3-ba91-4e75-9fdc-c0b6e1d1e532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "971b0ab3-ba91-4e75-9fdc-c0b6e1d1e532",
    "outputId": "07235476-7c93-40ef-e2ec-def456cc1c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                   object\n",
       "Symbol                 object\n",
       "Series                 object\n",
       "Prev Close            float64\n",
       "Open                  float64\n",
       "High                  float64\n",
       "Low                   float64\n",
       "Last                  float64\n",
       "Close                 float64\n",
       "VWAP                  float64\n",
       "Volume                  int64\n",
       "Turnover              float64\n",
       "Trades                float64\n",
       "Deliverable Volume    float64\n",
       "%Deliverble           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9eda3ec-8ecd-4369-a585-986138415993",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9eda3ec-8ecd-4369-a585-986138415993",
    "outputId": "f2d90bdc-fefb-4e45-bd2b-29eba3d75142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6348 entries, 0 to 6347\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Date                6348 non-null   object \n",
      " 1   Symbol              6348 non-null   object \n",
      " 2   Series              6348 non-null   object \n",
      " 3   Prev Close          6348 non-null   float64\n",
      " 4   Open                6348 non-null   float64\n",
      " 5   High                6348 non-null   float64\n",
      " 6   Low                 6348 non-null   float64\n",
      " 7   Last                5802 non-null   float64\n",
      " 8   Close               6348 non-null   float64\n",
      " 9   VWAP                6348 non-null   float64\n",
      " 10  Volume              6348 non-null   int64  \n",
      " 11  Turnover            6348 non-null   float64\n",
      " 12  Trades              2501 non-null   float64\n",
      " 13  Deliverable Volume  4843 non-null   float64\n",
      " 14  %Deliverble         4843 non-null   float64\n",
      "dtypes: float64(11), int64(1), object(3)\n",
      "memory usage: 744.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea23ece4-5c28-4ec8-a223-a29261977f1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea23ece4-5c28-4ec8-a223-a29261977f1f",
    "outputId": "06ea08b0-8dde-462d-e417-c611a9419b06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6348, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['Date','Close']]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3397d33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>1560.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>1580.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>1563.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>1571.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>1574.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Close\n",
       "0  2021-07-01  1560.40\n",
       "1  2021-06-30  1580.80\n",
       "2  2021-06-29  1563.05\n",
       "3  2021-06-28  1571.80\n",
       "4  2021-06-25  1574.20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ecfac7d-8fa0-4b47-97a0-d78a531d58de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ecfac7d-8fa0-4b47-97a0-d78a531d58de",
    "outputId": "f629f426-9932-4f7f-d692-47137b9a19a2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Close    Date_Xth      Xth\n",
      "0  2021-07-01  1560.40  2021-06-10  1424.30\n",
      "1  2021-06-30  1580.80  2021-06-09  1415.30\n",
      "2  2021-06-29  1563.05  2021-06-08  1412.95\n",
      "3  2021-06-28  1571.80  2021-06-07  1389.65\n",
      "4  2021-06-25  1574.20  2021-06-04  1385.65\n",
      "6348\n",
      "(6348, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_30672\\2246226591.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Date_Xth'] = df1['Date'].shift(-1* pred_days)\n",
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_30672\\2246226591.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Xth'] = df1['Close'].shift(-1* pred_days)\n"
     ]
    }
   ],
   "source": [
    "pred_days = 15  #choises are only 5,10, 15\n",
    "reward = 5\n",
    "risk =-1 * (reward/4) #1:4 Trade\n",
    "days_shape = 60\n",
    "eps = 500\n",
    "\n",
    "\n",
    "\n",
    "df1['Date_Xth'] = df1['Date'].shift(-1* pred_days)\n",
    "df1['Xth'] = df1['Close'].shift(-1* pred_days)\n",
    "\n",
    "df11 = df1.copy()\n",
    "print(df11.head())\n",
    "\n",
    "df11['Price_X+1th'] = df11['Close'].shift(-1*pred_days +1)\n",
    "df11['Price_X+2th'] = df11['Close'].shift(-1*pred_days +2)\n",
    "df11['Price_X+3th'] = df11['Close'].shift(-1*pred_days +3)\n",
    "df11['Price_X+4th'] = df11['Close'].shift(-1*pred_days +4)\n",
    "df11['Price_X+5th'] = df11['Close'].shift(-1*pred_days +5)\n",
    "\n",
    "if pred_days > 5:\n",
    "    df11['Price_X+6th'] = df11['Close'].shift(-1*pred_days +6)\n",
    "    df11['Price_X+7th'] = df11['Close'].shift(-1*pred_days +7)\n",
    "    df11['Price_X+8th'] = df11['Close'].shift(-1*pred_days +8)\n",
    "    df11['Price_X+9th'] = df11['Close'].shift(-1*pred_days +9)\n",
    "    df11['Price_X+10th'] = df11['Close'].shift(-1*pred_days +10)\n",
    "    \n",
    "if pred_days > 10:\n",
    "    df11['Price_X+11th'] = df11['Close'].shift(-1*pred_days +11)\n",
    "    df11['Price_X+12th'] = df11['Close'].shift(-1*pred_days +12)\n",
    "    df11['Price_X+13th'] = df11['Close'].shift(-1*pred_days +13)\n",
    "    df11['Price_X+14th'] = df11['Close'].shift(-1*pred_days +14)\n",
    "    df11['Price_X+15th'] = df11['Close']#.shift(-15)\n",
    "                                   \n",
    "print(len(df1.Close))\n",
    "print(df11.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2e952c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.25\n"
     ]
    }
   ],
   "source": [
    "print(risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff1b1cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Date_Xth</th>\n",
       "      <th>Xth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>1560.40</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>1424.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>1415.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>1412.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>1389.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>1385.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Close    Date_Xth      Xth\n",
       "0  2021-07-01  1560.40  2021-06-10  1424.30\n",
       "1  2021-06-30  1580.80  2021-06-09  1415.30\n",
       "2  2021-06-29  1563.05  2021-06-08  1412.95\n",
       "3  2021-06-28  1571.80  2021-06-07  1389.65\n",
       "4  2021-06-25  1574.20  2021-06-04  1385.65"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ae4c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Date_Xth</th>\n",
       "      <th>Xth</th>\n",
       "      <th>Price_X+1th</th>\n",
       "      <th>Price_X+2th</th>\n",
       "      <th>Price_X+3th</th>\n",
       "      <th>Price_X+4th</th>\n",
       "      <th>Price_X+5th</th>\n",
       "      <th>Price_X+6th</th>\n",
       "      <th>Price_X+7th</th>\n",
       "      <th>Price_X+8th</th>\n",
       "      <th>Price_X+9th</th>\n",
       "      <th>Price_X+10th</th>\n",
       "      <th>Price_X+11th</th>\n",
       "      <th>Price_X+12th</th>\n",
       "      <th>Price_X+13th</th>\n",
       "      <th>Price_X+14th</th>\n",
       "      <th>Price_X+15th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>1560.40</td>\n",
       "      <td>2021-06-10</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>1560.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1580.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>2021-06-07</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>2021-06-04</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>2021-06-03</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>1393.75</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>1405.05</td>\n",
       "      <td>1393.75</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>1402.25</td>\n",
       "      <td>1405.05</td>\n",
       "      <td>1393.75</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>1397.25</td>\n",
       "      <td>1402.25</td>\n",
       "      <td>1405.05</td>\n",
       "      <td>1393.75</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>1361.60</td>\n",
       "      <td>1397.25</td>\n",
       "      <td>1402.25</td>\n",
       "      <td>1405.05</td>\n",
       "      <td>1393.75</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>1473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>1461.80</td>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>1348.05</td>\n",
       "      <td>1361.60</td>\n",
       "      <td>1397.25</td>\n",
       "      <td>1402.25</td>\n",
       "      <td>1405.05</td>\n",
       "      <td>1393.75</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>1461.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>1446.90</td>\n",
       "      <td>2021-05-21</td>\n",
       "      <td>1354.50</td>\n",
       "      <td>1348.05</td>\n",
       "      <td>1361.60</td>\n",
       "      <td>1397.25</td>\n",
       "      <td>1402.25</td>\n",
       "      <td>1405.05</td>\n",
       "      <td>1393.75</td>\n",
       "      <td>1387.20</td>\n",
       "      <td>1378.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1385.65</td>\n",
       "      <td>1389.65</td>\n",
       "      <td>1412.95</td>\n",
       "      <td>1415.30</td>\n",
       "      <td>1424.30</td>\n",
       "      <td>1446.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date    Close    Date_Xth      Xth  Price_X+1th  Price_X+2th  \\\n",
       "0   2021-07-01  1560.40  2021-06-10  1424.30      1446.90      1461.80   \n",
       "1   2021-06-30  1580.80  2021-06-09  1415.30      1424.30      1446.90   \n",
       "2   2021-06-29  1563.05  2021-06-08  1412.95      1415.30      1424.30   \n",
       "3   2021-06-28  1571.80  2021-06-07  1389.65      1412.95      1415.30   \n",
       "4   2021-06-25  1574.20  2021-06-04  1385.65      1389.65      1412.95   \n",
       "5   2021-06-24  1559.20  2021-06-03  1389.65      1385.65      1389.65   \n",
       "6   2021-06-23  1503.15  2021-06-02  1378.65      1389.65      1385.65   \n",
       "7   2021-06-22  1511.85  2021-06-01  1387.20      1378.65      1389.65   \n",
       "8   2021-06-21  1500.30  2021-05-31  1393.75      1387.20      1378.65   \n",
       "9   2021-06-18  1503.30  2021-05-28  1405.05      1393.75      1387.20   \n",
       "10  2021-06-17  1495.30  2021-05-27  1402.25      1405.05      1393.75   \n",
       "11  2021-06-16  1480.60  2021-05-26  1397.25      1402.25      1405.05   \n",
       "12  2021-06-15  1473.90  2021-05-25  1361.60      1397.25      1402.25   \n",
       "13  2021-06-14  1461.80  2021-05-24  1348.05      1361.60      1397.25   \n",
       "14  2021-06-11  1446.90  2021-05-21  1354.50      1348.05      1361.60   \n",
       "\n",
       "    Price_X+3th  Price_X+4th  Price_X+5th  Price_X+6th  Price_X+7th  \\\n",
       "0       1473.90      1480.60      1495.30      1503.30      1500.30   \n",
       "1       1461.80      1473.90      1480.60      1495.30      1503.30   \n",
       "2       1446.90      1461.80      1473.90      1480.60      1495.30   \n",
       "3       1424.30      1446.90      1461.80      1473.90      1480.60   \n",
       "4       1415.30      1424.30      1446.90      1461.80      1473.90   \n",
       "5       1412.95      1415.30      1424.30      1446.90      1461.80   \n",
       "6       1389.65      1412.95      1415.30      1424.30      1446.90   \n",
       "7       1385.65      1389.65      1412.95      1415.30      1424.30   \n",
       "8       1389.65      1385.65      1389.65      1412.95      1415.30   \n",
       "9       1378.65      1389.65      1385.65      1389.65      1412.95   \n",
       "10      1387.20      1378.65      1389.65      1385.65      1389.65   \n",
       "11      1393.75      1387.20      1378.65      1389.65      1385.65   \n",
       "12      1405.05      1393.75      1387.20      1378.65      1389.65   \n",
       "13      1402.25      1405.05      1393.75      1387.20      1378.65   \n",
       "14      1397.25      1402.25      1405.05      1393.75      1387.20   \n",
       "\n",
       "    Price_X+8th  Price_X+9th  Price_X+10th  Price_X+11th  Price_X+12th  \\\n",
       "0       1511.85      1503.15       1559.20       1574.20       1571.80   \n",
       "1       1500.30      1511.85       1503.15       1559.20       1574.20   \n",
       "2       1503.30      1500.30       1511.85       1503.15       1559.20   \n",
       "3       1495.30      1503.30       1500.30       1511.85       1503.15   \n",
       "4       1480.60      1495.30       1503.30       1500.30       1511.85   \n",
       "5       1473.90      1480.60       1495.30       1503.30       1500.30   \n",
       "6       1461.80      1473.90       1480.60       1495.30       1503.30   \n",
       "7       1446.90      1461.80       1473.90       1480.60       1495.30   \n",
       "8       1424.30      1446.90       1461.80       1473.90       1480.60   \n",
       "9       1415.30      1424.30       1446.90       1461.80       1473.90   \n",
       "10      1412.95      1415.30       1424.30       1446.90       1461.80   \n",
       "11      1389.65      1412.95       1415.30       1424.30       1446.90   \n",
       "12      1385.65      1389.65       1412.95       1415.30       1424.30   \n",
       "13      1389.65      1385.65       1389.65       1412.95       1415.30   \n",
       "14      1378.65      1389.65       1385.65       1389.65       1412.95   \n",
       "\n",
       "    Price_X+13th  Price_X+14th  Price_X+15th  \n",
       "0        1563.05       1580.80       1560.40  \n",
       "1        1571.80       1563.05       1580.80  \n",
       "2        1574.20       1571.80       1563.05  \n",
       "3        1559.20       1574.20       1571.80  \n",
       "4        1503.15       1559.20       1574.20  \n",
       "5        1511.85       1503.15       1559.20  \n",
       "6        1500.30       1511.85       1503.15  \n",
       "7        1503.30       1500.30       1511.85  \n",
       "8        1495.30       1503.30       1500.30  \n",
       "9        1480.60       1495.30       1503.30  \n",
       "10       1473.90       1480.60       1495.30  \n",
       "11       1461.80       1473.90       1480.60  \n",
       "12       1446.90       1461.80       1473.90  \n",
       "13       1424.30       1446.90       1461.80  \n",
       "14       1415.30       1424.30       1446.90  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df11.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710816b",
   "metadata": {},
   "source": [
    "to do 8888888888888888888\n",
    "Note that when I label this Xth I should have correcponding date and not the T+pred_day date\n",
    "\n",
    "update: this is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc9583c-a755-4b0c-a166-2ed557e8ad38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7bc9583c-a755-4b0c-a166-2ed557e8ad38",
    "outputId": "1239918d-8fb3-4862-e5b6-133fb6d40cf5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_30672\\4132079558.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['temp'] = df1['Xth'] - df1['Xth'].shift(-1*i)\n",
      "C:\\Users\\abhij\\AppData\\Local\\Temp\\ipykernel_30672\\4132079558.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['temp'] = df1['temp']/df1['Xth']*100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631889</td>\n",
       "      <td>0.796883</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>2.713614</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>3.205083</td>\n",
       "      <td>2.604788</td>\n",
       "      <td>2.144913</td>\n",
       "      <td>1.351541</td>\n",
       "      <td>1.548129</td>\n",
       "      <td>...</td>\n",
       "      <td>4.953310</td>\n",
       "      <td>3.703574</td>\n",
       "      <td>3.756231</td>\n",
       "      <td>5.606263</td>\n",
       "      <td>6.122306</td>\n",
       "      <td>2.618830</td>\n",
       "      <td>2.829460</td>\n",
       "      <td>3.559643</td>\n",
       "      <td>3.471881</td>\n",
       "      <td>3.942287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166043</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.094962</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.589557</td>\n",
       "      <td>1.985445</td>\n",
       "      <td>1.522645</td>\n",
       "      <td>0.724228</td>\n",
       "      <td>0.922066</td>\n",
       "      <td>1.275348</td>\n",
       "      <td>...</td>\n",
       "      <td>3.091217</td>\n",
       "      <td>3.144210</td>\n",
       "      <td>5.006006</td>\n",
       "      <td>5.525330</td>\n",
       "      <td>1.999576</td>\n",
       "      <td>2.211545</td>\n",
       "      <td>2.946372</td>\n",
       "      <td>2.858051</td>\n",
       "      <td>3.331449</td>\n",
       "      <td>4.928284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.649032</td>\n",
       "      <td>1.932128</td>\n",
       "      <td>1.649032</td>\n",
       "      <td>2.427545</td>\n",
       "      <td>1.822428</td>\n",
       "      <td>1.358859</td>\n",
       "      <td>0.559114</td>\n",
       "      <td>0.757281</td>\n",
       "      <td>1.111150</td>\n",
       "      <td>3.634240</td>\n",
       "      <td>...</td>\n",
       "      <td>2.983120</td>\n",
       "      <td>4.848013</td>\n",
       "      <td>5.368201</td>\n",
       "      <td>1.836583</td>\n",
       "      <td>2.048905</td>\n",
       "      <td>2.784953</td>\n",
       "      <td>2.696486</td>\n",
       "      <td>3.170671</td>\n",
       "      <td>4.770162</td>\n",
       "      <td>5.463746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.295038</td>\n",
       "      <td>-1.108193</td>\n",
       "      <td>-0.906703</td>\n",
       "      <td>-0.546900</td>\n",
       "      <td>2.018494</td>\n",
       "      <td>2.993560</td>\n",
       "      <td>...</td>\n",
       "      <td>3.252618</td>\n",
       "      <td>3.781528</td>\n",
       "      <td>0.190695</td>\n",
       "      <td>0.406577</td>\n",
       "      <td>1.154967</td>\n",
       "      <td>1.065016</td>\n",
       "      <td>1.547152</td>\n",
       "      <td>3.173461</td>\n",
       "      <td>3.878674</td>\n",
       "      <td>5.249523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.288673</td>\n",
       "      <td>0.505178</td>\n",
       "      <td>-0.111861</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-1.400065</td>\n",
       "      <td>-1.197994</td>\n",
       "      <td>-0.837152</td>\n",
       "      <td>1.735648</td>\n",
       "      <td>2.713528</td>\n",
       "      <td>2.248042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.503771</td>\n",
       "      <td>-0.097427</td>\n",
       "      <td>0.119078</td>\n",
       "      <td>0.869628</td>\n",
       "      <td>0.779418</td>\n",
       "      <td>1.262945</td>\n",
       "      <td>2.893949</td>\n",
       "      <td>3.601198</td>\n",
       "      <td>4.976004</td>\n",
       "      <td>3.990907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.295038</td>\n",
       "      <td>-1.108193</td>\n",
       "      <td>-0.906703</td>\n",
       "      <td>-0.546900</td>\n",
       "      <td>2.018494</td>\n",
       "      <td>2.993560</td>\n",
       "      <td>2.529414</td>\n",
       "      <td>3.623214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190695</td>\n",
       "      <td>0.406577</td>\n",
       "      <td>1.154967</td>\n",
       "      <td>1.065016</td>\n",
       "      <td>1.547152</td>\n",
       "      <td>3.173461</td>\n",
       "      <td>3.878674</td>\n",
       "      <td>5.249523</td>\n",
       "      <td>4.267262</td>\n",
       "      <td>3.317382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.620172</td>\n",
       "      <td>-1.095274</td>\n",
       "      <td>-1.914917</td>\n",
       "      <td>-1.711820</td>\n",
       "      <td>-1.349146</td>\n",
       "      <td>1.236717</td>\n",
       "      <td>2.219563</td>\n",
       "      <td>1.751714</td>\n",
       "      <td>2.854241</td>\n",
       "      <td>3.021071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388061</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.275632</td>\n",
       "      <td>0.761615</td>\n",
       "      <td>2.400899</td>\n",
       "      <td>3.111740</td>\n",
       "      <td>4.493526</td>\n",
       "      <td>3.503427</td>\n",
       "      <td>2.545969</td>\n",
       "      <td>5.378450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.472174</td>\n",
       "      <td>-1.286765</td>\n",
       "      <td>-1.084919</td>\n",
       "      <td>-0.724481</td>\n",
       "      <td>1.845444</td>\n",
       "      <td>2.822232</td>\n",
       "      <td>2.357266</td>\n",
       "      <td>3.452999</td>\n",
       "      <td>3.618800</td>\n",
       "      <td>3.402537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.890283</td>\n",
       "      <td>1.373270</td>\n",
       "      <td>3.002451</td>\n",
       "      <td>3.708910</td>\n",
       "      <td>5.082180</td>\n",
       "      <td>4.098183</td>\n",
       "      <td>3.146626</td>\n",
       "      <td>5.961649</td>\n",
       "      <td>8.664937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.810762</td>\n",
       "      <td>-0.609865</td>\n",
       "      <td>-0.251121</td>\n",
       "      <td>2.306726</td>\n",
       "      <td>3.278924</td>\n",
       "      <td>2.816143</td>\n",
       "      <td>3.906726</td>\n",
       "      <td>4.071749</td>\n",
       "      <td>3.856502</td>\n",
       "      <td>4.617040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.356054</td>\n",
       "      <td>1.836771</td>\n",
       "      <td>3.458296</td>\n",
       "      <td>4.161435</td>\n",
       "      <td>5.528251</td>\n",
       "      <td>4.548879</td>\n",
       "      <td>3.601794</td>\n",
       "      <td>6.403587</td>\n",
       "      <td>9.094170</td>\n",
       "      <td>10.077130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.199281</td>\n",
       "      <td>0.555140</td>\n",
       "      <td>3.092417</td>\n",
       "      <td>4.056795</td>\n",
       "      <td>3.597737</td>\n",
       "      <td>4.679549</td>\n",
       "      <td>4.843244</td>\n",
       "      <td>4.629728</td>\n",
       "      <td>5.384150</td>\n",
       "      <td>6.309384</td>\n",
       "      <td>...</td>\n",
       "      <td>2.626241</td>\n",
       "      <td>4.234725</td>\n",
       "      <td>4.932209</td>\n",
       "      <td>6.288032</td>\n",
       "      <td>5.316537</td>\n",
       "      <td>4.377068</td>\n",
       "      <td>7.156329</td>\n",
       "      <td>9.825273</td>\n",
       "      <td>10.800327</td>\n",
       "      <td>9.287926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.631889  0.796883  2.432774  2.713614  2.432774  3.205083  2.604788   \n",
       "1  0.166043  1.812337  2.094962  1.812337  2.589557  1.985445  1.522645   \n",
       "2  1.649032  1.932128  1.649032  2.427545  1.822428  1.358859  0.559114   \n",
       "3  0.287842  0.000000  0.791566  0.176303 -0.295038 -1.108193 -0.906703   \n",
       "4 -0.288673  0.505178 -0.111861 -0.584563 -1.400065 -1.197994 -0.837152   \n",
       "5  0.791566  0.176303 -0.295038 -1.108193 -0.906703 -0.546900  2.018494   \n",
       "6 -0.620172 -1.095274 -1.914917 -1.711820 -1.349146  1.236717  2.219563   \n",
       "7 -0.472174 -1.286765 -1.084919 -0.724481  1.845444  2.822232  2.357266   \n",
       "8 -0.810762 -0.609865 -0.251121  2.306726  3.278924  2.816143  3.906726   \n",
       "9  0.199281  0.555140  3.092417  4.056795  3.597737  4.679549  4.843244   \n",
       "\n",
       "         7         8         9   ...        50        51        52        53  \\\n",
       "0  2.144913  1.351541  1.548129  ...  4.953310  3.703574  3.756231  5.606263   \n",
       "1  0.724228  0.922066  1.275348  ...  3.091217  3.144210  5.006006  5.525330   \n",
       "2  0.757281  1.111150  3.634240  ...  2.983120  4.848013  5.368201  1.836583   \n",
       "3 -0.546900  2.018494  2.993560  ...  3.252618  3.781528  0.190695  0.406577   \n",
       "4  1.735648  2.713528  2.248042  ...  3.503771 -0.097427  0.119078  0.869628   \n",
       "5  2.993560  2.529414  3.623214  ...  0.190695  0.406577  1.154967  1.065016   \n",
       "6  1.751714  2.854241  3.021071  ... -0.388061  0.366300  0.275632  0.761615   \n",
       "7  3.452999  3.618800  3.402537  ...  0.980392  0.890283  1.373270  3.002451   \n",
       "8  4.071749  3.856502  4.617040  ...  1.356054  1.836771  3.458296  4.161435   \n",
       "9  4.629728  5.384150  6.309384  ...  2.626241  4.234725  4.932209  6.288032   \n",
       "\n",
       "         54        55        56        57         58         59  \n",
       "0  6.122306  2.618830  2.829460  3.559643   3.471881   3.942287  \n",
       "1  1.999576  2.211545  2.946372  2.858051   3.331449   4.928284  \n",
       "2  2.048905  2.784953  2.696486  3.170671   4.770162   5.463746  \n",
       "3  1.154967  1.065016  1.547152  3.173461   3.878674   5.249523  \n",
       "4  0.779418  1.262945  2.893949  3.601198   4.976004   3.990907  \n",
       "5  1.547152  3.173461  3.878674  5.249523   4.267262   3.317382  \n",
       "6  2.400899  3.111740  4.493526  3.503427   2.545969   5.378450  \n",
       "7  3.708910  5.082180  4.098183  3.146626   5.961649   8.664937  \n",
       "8  5.528251  4.548879  3.601794  6.403587   9.094170  10.077130  \n",
       "9  5.316537  4.377068  7.156329  9.825273  10.800327   9.287926  \n",
       "\n",
       "[10 rows x 60 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "c1 = []\n",
    "for i in range(1,days_shape+1):\n",
    "    df1['temp'] = df1['Xth'] - df1['Xth'].shift(-1*i)\n",
    "    df1['temp'] = df1['temp']/df1['Xth']*100\n",
    "    c1.append(df1['temp'].to_numpy())\n",
    "\n",
    "print(len(c1))    \n",
    "df2 = pd.DataFrame(c1)\n",
    "df3 = df2.transpose()\n",
    "print(len(df3[0]))\n",
    "\n",
    "df3.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9f40cf7-dd88-407e-b8e4-46d3d9347d38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9f40cf7-dd88-407e-b8e4-46d3d9347d38",
    "outputId": "c1375cf0-f6b7-47d6-f6f2-35987bc4632a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6348, 60)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa913eaa-d634-4a7e-bf4b-d8a235d30bf1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa913eaa-d634-4a7e-bf4b-d8a235d30bf1",
    "outputId": "1a074627-6ace-4fe6-e627-094a387348b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63188935, 0.79688268, 2.43277399, ..., 3.55964333, 3.47188092,\n",
       "        3.94228744],\n",
       "       [0.16604254, 1.81233661, 2.0949622 , ..., 2.8580513 , 3.33144916,\n",
       "        4.92828376],\n",
       "       [1.64903217, 1.93212782, 1.64903217, ..., 3.17067129, 4.77016172,\n",
       "        5.46374606],\n",
       "       ...,\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 =df3.to_numpy()\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "880304ee-74c8-4bb5-82a1-ca7a0472b028",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "880304ee-74c8-4bb5-82a1-ca7a0472b028",
    "outputId": "73b71715-819e-4c42-d28a-57e573368bdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6348"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "829fed7d-8de6-4b65-b88c-ebb9fe12337d",
   "metadata": {
    "id": "829fed7d-8de6-4b65-b88c-ebb9fe12337d"
   },
   "outputs": [],
   "source": [
    "c3 =[]\n",
    "\n",
    "for i in range(int(len(c2)-days_shape)):\n",
    "      \n",
    "    c6 = np.concatenate((c2[i:i+days_shape]))\n",
    "    \n",
    "    c3.append(c6)\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff0b48d2-7d70-44cc-b835-d6ec671befd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff0b48d2-7d70-44cc-b835-d6ec671befd8",
    "outputId": "6155793c-8028-409e-a3fb-7a75989ac987"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.16604254,  1.81233661,  2.0949622 , ..., 14.79735409,\n",
       "        15.60866864, 14.8814092 ]),\n",
       " array([ 1.64903217,  1.93212782,  1.64903217, ..., 14.19122292,\n",
       "        13.45174836, 13.55207908])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c3[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90c7224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6288"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d02ef96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80e6c0b3-2c32-4bbe-96a1-018ad6741f2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "80e6c0b3-2c32-4bbe-96a1-018ad6741f2c",
    "outputId": "2f5f8ca0-2b72-4f93-8a78-750aca710a5a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3590</th>\n",
       "      <th>3591</th>\n",
       "      <th>3592</th>\n",
       "      <th>3593</th>\n",
       "      <th>3594</th>\n",
       "      <th>3595</th>\n",
       "      <th>3596</th>\n",
       "      <th>3597</th>\n",
       "      <th>3598</th>\n",
       "      <th>3599</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631889</td>\n",
       "      <td>0.796883</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>2.713614</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>3.205083</td>\n",
       "      <td>2.604788</td>\n",
       "      <td>2.144913</td>\n",
       "      <td>1.351541</td>\n",
       "      <td>1.548129</td>\n",
       "      <td>...</td>\n",
       "      <td>9.059170</td>\n",
       "      <td>9.786522</td>\n",
       "      <td>10.095647</td>\n",
       "      <td>8.859148</td>\n",
       "      <td>11.226679</td>\n",
       "      <td>14.368840</td>\n",
       "      <td>13.459650</td>\n",
       "      <td>15.685347</td>\n",
       "      <td>15.212569</td>\n",
       "      <td>16.019929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166043</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.094962</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.589557</td>\n",
       "      <td>1.985445</td>\n",
       "      <td>1.522645</td>\n",
       "      <td>0.724228</td>\n",
       "      <td>0.922066</td>\n",
       "      <td>1.275348</td>\n",
       "      <td>...</td>\n",
       "      <td>9.344736</td>\n",
       "      <td>9.655374</td>\n",
       "      <td>8.412820</td>\n",
       "      <td>10.791945</td>\n",
       "      <td>13.949494</td>\n",
       "      <td>13.035851</td>\n",
       "      <td>15.272448</td>\n",
       "      <td>14.797354</td>\n",
       "      <td>15.608669</td>\n",
       "      <td>14.881409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.649032</td>\n",
       "      <td>1.932128</td>\n",
       "      <td>1.649032</td>\n",
       "      <td>2.427545</td>\n",
       "      <td>1.822428</td>\n",
       "      <td>1.358859</td>\n",
       "      <td>0.559114</td>\n",
       "      <td>0.757281</td>\n",
       "      <td>1.111150</td>\n",
       "      <td>3.634240</td>\n",
       "      <td>...</td>\n",
       "      <td>8.137936</td>\n",
       "      <td>6.874512</td>\n",
       "      <td>9.293597</td>\n",
       "      <td>12.504180</td>\n",
       "      <td>11.575192</td>\n",
       "      <td>13.849355</td>\n",
       "      <td>13.366281</td>\n",
       "      <td>14.191223</td>\n",
       "      <td>13.451748</td>\n",
       "      <td>13.552079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.295038</td>\n",
       "      <td>-1.108193</td>\n",
       "      <td>-0.906703</td>\n",
       "      <td>-0.546900</td>\n",
       "      <td>2.018494</td>\n",
       "      <td>2.993560</td>\n",
       "      <td>...</td>\n",
       "      <td>6.191278</td>\n",
       "      <td>8.628112</td>\n",
       "      <td>11.862250</td>\n",
       "      <td>10.926446</td>\n",
       "      <td>13.217294</td>\n",
       "      <td>12.730676</td>\n",
       "      <td>13.561669</td>\n",
       "      <td>12.816770</td>\n",
       "      <td>12.917836</td>\n",
       "      <td>12.577204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.288673</td>\n",
       "      <td>0.505178</td>\n",
       "      <td>-0.111861</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-1.400065</td>\n",
       "      <td>-1.197994</td>\n",
       "      <td>-0.837152</td>\n",
       "      <td>1.735648</td>\n",
       "      <td>2.713528</td>\n",
       "      <td>2.248042</td>\n",
       "      <td>...</td>\n",
       "      <td>7.306144</td>\n",
       "      <td>10.587074</td>\n",
       "      <td>9.637731</td>\n",
       "      <td>11.961722</td>\n",
       "      <td>11.468064</td>\n",
       "      <td>12.311081</td>\n",
       "      <td>11.555404</td>\n",
       "      <td>11.657933</td>\n",
       "      <td>11.312372</td>\n",
       "      <td>10.746563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.295038</td>\n",
       "      <td>-1.108193</td>\n",
       "      <td>-0.906703</td>\n",
       "      <td>-0.546900</td>\n",
       "      <td>2.018494</td>\n",
       "      <td>2.993560</td>\n",
       "      <td>2.529414</td>\n",
       "      <td>3.623214</td>\n",
       "      <td>...</td>\n",
       "      <td>11.504491</td>\n",
       "      <td>10.564889</td>\n",
       "      <td>12.865036</td>\n",
       "      <td>12.376442</td>\n",
       "      <td>13.210809</td>\n",
       "      <td>12.462886</td>\n",
       "      <td>12.564363</td>\n",
       "      <td>12.222348</td>\n",
       "      <td>11.662344</td>\n",
       "      <td>13.304769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.620172</td>\n",
       "      <td>-1.095274</td>\n",
       "      <td>-1.914917</td>\n",
       "      <td>-1.711820</td>\n",
       "      <td>-1.349146</td>\n",
       "      <td>1.236717</td>\n",
       "      <td>2.219563</td>\n",
       "      <td>1.751714</td>\n",
       "      <td>2.854241</td>\n",
       "      <td>3.021071</td>\n",
       "      <td>...</td>\n",
       "      <td>11.443564</td>\n",
       "      <td>13.721112</td>\n",
       "      <td>13.237319</td>\n",
       "      <td>14.063489</td>\n",
       "      <td>13.322913</td>\n",
       "      <td>13.423393</td>\n",
       "      <td>13.084738</td>\n",
       "      <td>12.530237</td>\n",
       "      <td>14.156526</td>\n",
       "      <td>14.889658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.472174</td>\n",
       "      <td>-1.286765</td>\n",
       "      <td>-1.084919</td>\n",
       "      <td>-0.724481</td>\n",
       "      <td>1.845444</td>\n",
       "      <td>2.822232</td>\n",
       "      <td>2.357266</td>\n",
       "      <td>3.452999</td>\n",
       "      <td>3.618800</td>\n",
       "      <td>3.402537</td>\n",
       "      <td>...</td>\n",
       "      <td>11.138367</td>\n",
       "      <td>10.640092</td>\n",
       "      <td>11.490993</td>\n",
       "      <td>10.728248</td>\n",
       "      <td>10.831736</td>\n",
       "      <td>10.482944</td>\n",
       "      <td>9.911844</td>\n",
       "      <td>11.586815</td>\n",
       "      <td>12.341893</td>\n",
       "      <td>13.020314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.810762</td>\n",
       "      <td>-0.609865</td>\n",
       "      <td>-0.251121</td>\n",
       "      <td>2.306726</td>\n",
       "      <td>3.278924</td>\n",
       "      <td>2.816143</td>\n",
       "      <td>3.906726</td>\n",
       "      <td>4.071749</td>\n",
       "      <td>3.856502</td>\n",
       "      <td>4.617040</td>\n",
       "      <td>...</td>\n",
       "      <td>7.995264</td>\n",
       "      <td>8.871350</td>\n",
       "      <td>8.086030</td>\n",
       "      <td>8.192581</td>\n",
       "      <td>7.833465</td>\n",
       "      <td>7.245462</td>\n",
       "      <td>8.970008</td>\n",
       "      <td>9.747435</td>\n",
       "      <td>10.445935</td>\n",
       "      <td>11.093133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.199281</td>\n",
       "      <td>0.555140</td>\n",
       "      <td>3.092417</td>\n",
       "      <td>4.056795</td>\n",
       "      <td>3.597737</td>\n",
       "      <td>4.679549</td>\n",
       "      <td>4.843244</td>\n",
       "      <td>4.629728</td>\n",
       "      <td>5.384150</td>\n",
       "      <td>6.309384</td>\n",
       "      <td>...</td>\n",
       "      <td>7.875209</td>\n",
       "      <td>7.081305</td>\n",
       "      <td>7.189021</td>\n",
       "      <td>6.825979</td>\n",
       "      <td>6.231549</td>\n",
       "      <td>7.974946</td>\n",
       "      <td>8.760871</td>\n",
       "      <td>9.467007</td>\n",
       "      <td>10.121280</td>\n",
       "      <td>8.968324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 3600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.631889  0.796883  2.432774  2.713614  2.432774  3.205083  2.604788   \n",
       "1  0.166043  1.812337  2.094962  1.812337  2.589557  1.985445  1.522645   \n",
       "2  1.649032  1.932128  1.649032  2.427545  1.822428  1.358859  0.559114   \n",
       "3  0.287842  0.000000  0.791566  0.176303 -0.295038 -1.108193 -0.906703   \n",
       "4 -0.288673  0.505178 -0.111861 -0.584563 -1.400065 -1.197994 -0.837152   \n",
       "5  0.791566  0.176303 -0.295038 -1.108193 -0.906703 -0.546900  2.018494   \n",
       "6 -0.620172 -1.095274 -1.914917 -1.711820 -1.349146  1.236717  2.219563   \n",
       "7 -0.472174 -1.286765 -1.084919 -0.724481  1.845444  2.822232  2.357266   \n",
       "8 -0.810762 -0.609865 -0.251121  2.306726  3.278924  2.816143  3.906726   \n",
       "9  0.199281  0.555140  3.092417  4.056795  3.597737  4.679549  4.843244   \n",
       "\n",
       "       7         8         9     ...       3590       3591       3592  \\\n",
       "0  2.144913  1.351541  1.548129  ...   9.059170   9.786522  10.095647   \n",
       "1  0.724228  0.922066  1.275348  ...   9.344736   9.655374   8.412820   \n",
       "2  0.757281  1.111150  3.634240  ...   8.137936   6.874512   9.293597   \n",
       "3 -0.546900  2.018494  2.993560  ...   6.191278   8.628112  11.862250   \n",
       "4  1.735648  2.713528  2.248042  ...   7.306144  10.587074   9.637731   \n",
       "5  2.993560  2.529414  3.623214  ...  11.504491  10.564889  12.865036   \n",
       "6  1.751714  2.854241  3.021071  ...  11.443564  13.721112  13.237319   \n",
       "7  3.452999  3.618800  3.402537  ...  11.138367  10.640092  11.490993   \n",
       "8  4.071749  3.856502  4.617040  ...   7.995264   8.871350   8.086030   \n",
       "9  4.629728  5.384150  6.309384  ...   7.875209   7.081305   7.189021   \n",
       "\n",
       "        3593       3594       3595       3596       3597       3598       3599  \n",
       "0   8.859148  11.226679  14.368840  13.459650  15.685347  15.212569  16.019929  \n",
       "1  10.791945  13.949494  13.035851  15.272448  14.797354  15.608669  14.881409  \n",
       "2  12.504180  11.575192  13.849355  13.366281  14.191223  13.451748  13.552079  \n",
       "3  10.926446  13.217294  12.730676  13.561669  12.816770  12.917836  12.577204  \n",
       "4  11.961722  11.468064  12.311081  11.555404  11.657933  11.312372  10.746563  \n",
       "5  12.376442  13.210809  12.462886  12.564363  12.222348  11.662344  13.304769  \n",
       "6  14.063489  13.322913  13.423393  13.084738  12.530237  14.156526  14.889658  \n",
       "7  10.728248  10.831736  10.482944   9.911844  11.586815  12.341893  13.020314  \n",
       "8   8.192581   7.833465   7.245462   8.970008   9.747435  10.445935  11.093133  \n",
       "9   6.825979   6.231549   7.974946   8.760871   9.467007  10.121280   8.968324  \n",
       "\n",
       "[10 rows x 3600 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame(c3)\n",
    "df4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffbaa021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3590</th>\n",
       "      <th>3591</th>\n",
       "      <th>3592</th>\n",
       "      <th>3593</th>\n",
       "      <th>3594</th>\n",
       "      <th>3595</th>\n",
       "      <th>3596</th>\n",
       "      <th>3597</th>\n",
       "      <th>3598</th>\n",
       "      <th>3599</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>6288.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6223.000000</td>\n",
       "      <td>6222.000000</td>\n",
       "      <td>6221.000000</td>\n",
       "      <td>6220.000000</td>\n",
       "      <td>6219.000000</td>\n",
       "      <td>6218.000000</td>\n",
       "      <td>6217.000000</td>\n",
       "      <td>6216.000000</td>\n",
       "      <td>6215.000000</td>\n",
       "      <td>6214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.071226</td>\n",
       "      <td>-0.145399</td>\n",
       "      <td>-0.218138</td>\n",
       "      <td>-0.285762</td>\n",
       "      <td>-0.354349</td>\n",
       "      <td>-0.420235</td>\n",
       "      <td>-0.483184</td>\n",
       "      <td>-0.546482</td>\n",
       "      <td>-0.606661</td>\n",
       "      <td>-0.667541</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.663425</td>\n",
       "      <td>-2.711439</td>\n",
       "      <td>-2.760493</td>\n",
       "      <td>-2.809555</td>\n",
       "      <td>-2.858397</td>\n",
       "      <td>-2.909519</td>\n",
       "      <td>-2.961841</td>\n",
       "      <td>-3.014186</td>\n",
       "      <td>-3.065655</td>\n",
       "      <td>-3.116481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.529656</td>\n",
       "      <td>7.833385</td>\n",
       "      <td>9.592232</td>\n",
       "      <td>10.974928</td>\n",
       "      <td>12.233712</td>\n",
       "      <td>13.351308</td>\n",
       "      <td>14.341027</td>\n",
       "      <td>15.276267</td>\n",
       "      <td>16.099011</td>\n",
       "      <td>16.872291</td>\n",
       "      <td>...</td>\n",
       "      <td>33.194390</td>\n",
       "      <td>33.471990</td>\n",
       "      <td>33.751554</td>\n",
       "      <td>34.026659</td>\n",
       "      <td>34.289037</td>\n",
       "      <td>34.562833</td>\n",
       "      <td>34.820251</td>\n",
       "      <td>35.084829</td>\n",
       "      <td>35.337446</td>\n",
       "      <td>35.592221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-292.113856</td>\n",
       "      <td>-296.557354</td>\n",
       "      <td>-297.352357</td>\n",
       "      <td>-293.290477</td>\n",
       "      <td>-296.718015</td>\n",
       "      <td>-308.511740</td>\n",
       "      <td>-313.141061</td>\n",
       "      <td>-313.969310</td>\n",
       "      <td>-305.965919</td>\n",
       "      <td>-306.779784</td>\n",
       "      <td>...</td>\n",
       "      <td>-281.974020</td>\n",
       "      <td>-281.137563</td>\n",
       "      <td>-292.468109</td>\n",
       "      <td>-298.284341</td>\n",
       "      <td>-301.220189</td>\n",
       "      <td>-297.947865</td>\n",
       "      <td>-296.446663</td>\n",
       "      <td>-298.864855</td>\n",
       "      <td>-298.583842</td>\n",
       "      <td>-294.631170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.006877</td>\n",
       "      <td>-1.433982</td>\n",
       "      <td>-1.733326</td>\n",
       "      <td>-1.888687</td>\n",
       "      <td>-2.049189</td>\n",
       "      <td>-2.193542</td>\n",
       "      <td>-2.271213</td>\n",
       "      <td>-2.415636</td>\n",
       "      <td>-2.510533</td>\n",
       "      <td>-2.631908</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.310334</td>\n",
       "      <td>-8.408965</td>\n",
       "      <td>-8.616935</td>\n",
       "      <td>-8.727045</td>\n",
       "      <td>-8.933200</td>\n",
       "      <td>-9.013086</td>\n",
       "      <td>-9.194470</td>\n",
       "      <td>-9.202198</td>\n",
       "      <td>-9.417214</td>\n",
       "      <td>-9.591307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.055224</td>\n",
       "      <td>0.150523</td>\n",
       "      <td>0.290779</td>\n",
       "      <td>0.434047</td>\n",
       "      <td>0.505609</td>\n",
       "      <td>0.625440</td>\n",
       "      <td>0.766959</td>\n",
       "      <td>0.834550</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>1.016288</td>\n",
       "      <td>...</td>\n",
       "      <td>3.201619</td>\n",
       "      <td>3.341554</td>\n",
       "      <td>3.279064</td>\n",
       "      <td>3.397029</td>\n",
       "      <td>3.295601</td>\n",
       "      <td>3.389397</td>\n",
       "      <td>3.445942</td>\n",
       "      <td>3.498606</td>\n",
       "      <td>3.454958</td>\n",
       "      <td>3.410112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.185652</td>\n",
       "      <td>1.799568</td>\n",
       "      <td>2.252095</td>\n",
       "      <td>2.668881</td>\n",
       "      <td>3.017616</td>\n",
       "      <td>3.432825</td>\n",
       "      <td>3.773066</td>\n",
       "      <td>4.104045</td>\n",
       "      <td>4.341847</td>\n",
       "      <td>4.718248</td>\n",
       "      <td>...</td>\n",
       "      <td>12.302402</td>\n",
       "      <td>12.431008</td>\n",
       "      <td>12.716971</td>\n",
       "      <td>12.874435</td>\n",
       "      <td>13.039263</td>\n",
       "      <td>13.291931</td>\n",
       "      <td>13.521111</td>\n",
       "      <td>13.800771</td>\n",
       "      <td>14.024126</td>\n",
       "      <td>14.074975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.372626</td>\n",
       "      <td>20.099103</td>\n",
       "      <td>20.617289</td>\n",
       "      <td>26.497492</td>\n",
       "      <td>31.942108</td>\n",
       "      <td>34.032822</td>\n",
       "      <td>32.375192</td>\n",
       "      <td>33.688088</td>\n",
       "      <td>35.012032</td>\n",
       "      <td>39.756999</td>\n",
       "      <td>...</td>\n",
       "      <td>57.374569</td>\n",
       "      <td>56.123079</td>\n",
       "      <td>53.901601</td>\n",
       "      <td>55.181272</td>\n",
       "      <td>54.313326</td>\n",
       "      <td>52.743846</td>\n",
       "      <td>52.817114</td>\n",
       "      <td>53.120111</td>\n",
       "      <td>53.228165</td>\n",
       "      <td>53.307343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 3600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2            3            4     \\\n",
       "count  6288.000000  6288.000000  6288.000000  6288.000000  6288.000000   \n",
       "mean     -0.071226    -0.145399    -0.218138    -0.285762    -0.354349   \n",
       "std       5.529656     7.833385     9.592232    10.974928    12.233712   \n",
       "min    -292.113856  -296.557354  -297.352357  -293.290477  -296.718015   \n",
       "25%      -1.006877    -1.433982    -1.733326    -1.888687    -2.049189   \n",
       "50%       0.055224     0.150523     0.290779     0.434047     0.505609   \n",
       "75%       1.185652     1.799568     2.252095     2.668881     3.017616   \n",
       "max      14.372626    20.099103    20.617289    26.497492    31.942108   \n",
       "\n",
       "              5            6            7            8            9     ...  \\\n",
       "count  6288.000000  6288.000000  6288.000000  6288.000000  6288.000000  ...   \n",
       "mean     -0.420235    -0.483184    -0.546482    -0.606661    -0.667541  ...   \n",
       "std      13.351308    14.341027    15.276267    16.099011    16.872291  ...   \n",
       "min    -308.511740  -313.141061  -313.969310  -305.965919  -306.779784  ...   \n",
       "25%      -2.193542    -2.271213    -2.415636    -2.510533    -2.631908  ...   \n",
       "50%       0.625440     0.766959     0.834550     0.937322     1.016288  ...   \n",
       "75%       3.432825     3.773066     4.104045     4.341847     4.718248  ...   \n",
       "max      34.032822    32.375192    33.688088    35.012032    39.756999  ...   \n",
       "\n",
       "              3590         3591         3592         3593         3594  \\\n",
       "count  6223.000000  6222.000000  6221.000000  6220.000000  6219.000000   \n",
       "mean     -2.663425    -2.711439    -2.760493    -2.809555    -2.858397   \n",
       "std      33.194390    33.471990    33.751554    34.026659    34.289037   \n",
       "min    -281.974020  -281.137563  -292.468109  -298.284341  -301.220189   \n",
       "25%      -8.310334    -8.408965    -8.616935    -8.727045    -8.933200   \n",
       "50%       3.201619     3.341554     3.279064     3.397029     3.295601   \n",
       "75%      12.302402    12.431008    12.716971    12.874435    13.039263   \n",
       "max      57.374569    56.123079    53.901601    55.181272    54.313326   \n",
       "\n",
       "              3595         3596         3597         3598         3599  \n",
       "count  6218.000000  6217.000000  6216.000000  6215.000000  6214.000000  \n",
       "mean     -2.909519    -2.961841    -3.014186    -3.065655    -3.116481  \n",
       "std      34.562833    34.820251    35.084829    35.337446    35.592221  \n",
       "min    -297.947865  -296.446663  -298.864855  -298.583842  -294.631170  \n",
       "25%      -9.013086    -9.194470    -9.202198    -9.417214    -9.591307  \n",
       "50%       3.389397     3.445942     3.498606     3.454958     3.410112  \n",
       "75%      13.291931    13.521111    13.800771    14.024126    14.074975  \n",
       "max      52.743846    52.817114    53.120111    53.228165    53.307343  \n",
       "\n",
       "[8 rows x 3600 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "079e25aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "079e25aa",
    "outputId": "de5df3bf-5eeb-43ea-ba2a-519d1f20b14c",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6288, 3600)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1e62f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6288, 3600)\n",
      "(6348, 19)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df4_with_labels = df4.copy()\n",
    "df4_with_labels['Xth'] = df1.loc[:df4.shape[0]-1,'Xth']\n",
    "df4_with_labels['Date_Xth'] = df1.loc[:df4.shape[0]-1,'Date_Xth']\n",
    "df4_with_labels['Close'] = df1.loc[:df4.shape[0]-1,'Close']\n",
    "print(df4.shape)\n",
    "print(df11.shape)\n",
    "df4_with_labels['Price_X+1th'] = df11.loc[:df4.shape[0]-1,'Price_X+1th']\n",
    "df4_with_labels['Price_X+2th'] = df11.loc[:df4.shape[0]-1,'Price_X+2th']\n",
    "df4_with_labels['Price_X+3th'] =  df11.loc[:df4.shape[0]-1,'Price_X+3th'] \n",
    "df4_with_labels['Price_X+4th'] = df11.loc[:df4.shape[0]-1,'Price_X+4th']\n",
    "df4_with_labels['Price_X+5th'] = df11.loc[:df4.shape[0]-1,'Price_X+5th']\n",
    "\n",
    "if pred_days > 5:\n",
    "    df4_with_labels['Price_X+6th'] = df11.loc[:df4.shape[0]-1,'Price_X+6th']\n",
    "    df4_with_labels['Price_X+7th'] = df11.loc[:df4.shape[0]-1,'Price_X+7th']\n",
    "    df4_with_labels['Price_X+8th'] = df11.loc[:df4.shape[0]-1,'Price_X+8th']\n",
    "    df4_with_labels['Price_X+9th'] = df11.loc[:df4.shape[0]-1,'Price_X+9th']\n",
    "    df4_with_labels['Price_X+10th'] = df11.loc[:df4.shape[0]-1,'Price_X+10th']\n",
    "    \n",
    "if pred_days > 10:\n",
    "    df4_with_labels['Price_X+11th'] = df11.loc[:df4.shape[0]-1,'Price_X+11th']\n",
    "    df4_with_labels['Price_X+12th'] = df11.loc[:df4.shape[0]-1,'Price_X+12th']\n",
    "    df4_with_labels['Price_X+13th'] = df11.loc[:df4.shape[0]-1,'Price_X+13th']\n",
    "    df4_with_labels['Price_X+14th'] = df11.loc[:df4.shape[0]-1,'Price_X+14th']\n",
    "    df4_with_labels['Price_X+15th'] = df11.loc[:df4.shape[0]-1,'Price_X+15th']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82d42b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6288, 3618)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_with_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e81e5",
   "metadata": {},
   "source": [
    "This is the mail data set \n",
    "df4_with_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2b44ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_X+6th</th>\n",
       "      <th>Price_X+7th</th>\n",
       "      <th>Price_X+8th</th>\n",
       "      <th>Price_X+9th</th>\n",
       "      <th>Price_X+10th</th>\n",
       "      <th>Price_X+11th</th>\n",
       "      <th>Price_X+12th</th>\n",
       "      <th>Price_X+13th</th>\n",
       "      <th>Price_X+14th</th>\n",
       "      <th>Price_X+15th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631889</td>\n",
       "      <td>0.796883</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>2.713614</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>3.205083</td>\n",
       "      <td>2.604788</td>\n",
       "      <td>2.144913</td>\n",
       "      <td>1.351541</td>\n",
       "      <td>1.548129</td>\n",
       "      <td>...</td>\n",
       "      <td>1503.3</td>\n",
       "      <td>1500.3</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>1560.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166043</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.094962</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.589557</td>\n",
       "      <td>1.985445</td>\n",
       "      <td>1.522645</td>\n",
       "      <td>0.724228</td>\n",
       "      <td>0.922066</td>\n",
       "      <td>1.275348</td>\n",
       "      <td>...</td>\n",
       "      <td>1495.3</td>\n",
       "      <td>1503.3</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1580.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.649032</td>\n",
       "      <td>1.932128</td>\n",
       "      <td>1.649032</td>\n",
       "      <td>2.427545</td>\n",
       "      <td>1.822428</td>\n",
       "      <td>1.358859</td>\n",
       "      <td>0.559114</td>\n",
       "      <td>0.757281</td>\n",
       "      <td>1.111150</td>\n",
       "      <td>3.634240</td>\n",
       "      <td>...</td>\n",
       "      <td>1480.6</td>\n",
       "      <td>1495.3</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.295038</td>\n",
       "      <td>-1.108193</td>\n",
       "      <td>-0.906703</td>\n",
       "      <td>-0.546900</td>\n",
       "      <td>2.018494</td>\n",
       "      <td>2.993560</td>\n",
       "      <td>...</td>\n",
       "      <td>1473.9</td>\n",
       "      <td>1480.6</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.288673</td>\n",
       "      <td>0.505178</td>\n",
       "      <td>-0.111861</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-1.400065</td>\n",
       "      <td>-1.197994</td>\n",
       "      <td>-0.837152</td>\n",
       "      <td>1.735648</td>\n",
       "      <td>2.713528</td>\n",
       "      <td>2.248042</td>\n",
       "      <td>...</td>\n",
       "      <td>1461.8</td>\n",
       "      <td>1473.9</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3618 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.631889  0.796883  2.432774  2.713614  2.432774  3.205083  2.604788   \n",
       "1  0.166043  1.812337  2.094962  1.812337  2.589557  1.985445  1.522645   \n",
       "2  1.649032  1.932128  1.649032  2.427545  1.822428  1.358859  0.559114   \n",
       "3  0.287842  0.000000  0.791566  0.176303 -0.295038 -1.108193 -0.906703   \n",
       "4 -0.288673  0.505178 -0.111861 -0.584563 -1.400065 -1.197994 -0.837152   \n",
       "\n",
       "          7         8         9  ...  Price_X+6th  Price_X+7th  Price_X+8th  \\\n",
       "0  2.144913  1.351541  1.548129  ...       1503.3       1500.3      1511.85   \n",
       "1  0.724228  0.922066  1.275348  ...       1495.3       1503.3      1500.30   \n",
       "2  0.757281  1.111150  3.634240  ...       1480.6       1495.3      1503.30   \n",
       "3 -0.546900  2.018494  2.993560  ...       1473.9       1480.6      1495.30   \n",
       "4  1.735648  2.713528  2.248042  ...       1461.8       1473.9      1480.60   \n",
       "\n",
       "   Price_X+9th  Price_X+10th  Price_X+11th  Price_X+12th  Price_X+13th  \\\n",
       "0      1503.15       1559.20       1574.20       1571.80       1563.05   \n",
       "1      1511.85       1503.15       1559.20       1574.20       1571.80   \n",
       "2      1500.30       1511.85       1503.15       1559.20       1574.20   \n",
       "3      1503.30       1500.30       1511.85       1503.15       1559.20   \n",
       "4      1495.30       1503.30       1500.30       1511.85       1503.15   \n",
       "\n",
       "   Price_X+14th  Price_X+15th  \n",
       "0       1580.80       1560.40  \n",
       "1       1563.05       1580.80  \n",
       "2       1571.80       1563.05  \n",
       "3       1574.20       1571.80  \n",
       "4       1559.20       1574.20  \n",
       "\n",
       "[5 rows x 3618 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_with_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e10c159",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e10c159",
    "outputId": "867af6c5-9b49-4543-bb30-35684f534f91"
   },
   "outputs": [],
   "source": [
    "#df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eZjVvVrXTT6",
   "metadata": {
    "id": "0eZjVvVrXTT6"
   },
   "outputs": [],
   "source": [
    "#aes = df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03fda546",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03fda546",
    "outputId": "45128f1e-6e0c-41fa-ca52-f892599cf426"
   },
   "outputs": [],
   "source": [
    "#df4['Close'] = df1.iloc[:aes]['Close']\n",
    "\n",
    "#df4['Xth'] = df1.iloc[:aes]['Xth']\n",
    "#df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a77df552-f1e7-468e-b7b3-1e4de33ddf96",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "a77df552-f1e7-468e-b7b3-1e4de33ddf96",
    "outputId": "a9d23c5c-3236-4446-fa75-e10ec0689964"
   },
   "outputs": [],
   "source": [
    "#df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db71c2a8-3753-4466-9b4d-2fee0f741c70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db71c2a8-3753-4466-9b4d-2fee0f741c70",
    "outputId": "b9750366-f531-4514-a4b0-c6cfa6b40b1e"
   },
   "outputs": [],
   "source": [
    "#df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92d00432-3400-4f75-afc9-50fa4c44d3a7",
   "metadata": {
    "id": "92d00432-3400-4f75-afc9-50fa4c44d3a7"
   },
   "outputs": [],
   "source": [
    "df5 = df4_with_labels.copy()\n",
    "df5 = df5.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f397ea72-2124-4b30-b27e-e69b6ecbd722",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f397ea72-2124-4b30-b27e-e69b6ecbd722",
    "outputId": "3e945a34-cb52-4377-81e7-127cbf1201af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6214, 3618)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a7f9991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xth                 1424.3\n",
       "Date_Xth        2021-06-10\n",
       "Close               1560.4\n",
       "Price_X+1th         1446.9\n",
       "Price_X+2th         1461.8\n",
       "Price_X+3th         1473.9\n",
       "Price_X+4th         1480.6\n",
       "Price_X+5th         1495.3\n",
       "Price_X+6th         1503.3\n",
       "Price_X+7th         1500.3\n",
       "Price_X+8th        1511.85\n",
       "Price_X+9th        1503.15\n",
       "Price_X+10th        1559.2\n",
       "Price_X+11th        1574.2\n",
       "Price_X+12th        1571.8\n",
       "Price_X+13th       1563.05\n",
       "Price_X+14th        1580.8\n",
       "Price_X+15th        1560.4\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.iloc[0,days_shape*days_shape:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d050b4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560.4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.iloc[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cc0ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Xth                 1424.3\n",
       "Date_Xth        2021-06-10\n",
       "Close               1560.4\n",
       "Price_X+1th         1446.9\n",
       "Price_X+2th         1461.8\n",
       "Price_X+3th         1473.9\n",
       "Price_X+4th         1480.6\n",
       "Price_X+5th         1495.3\n",
       "Price_X+6th         1503.3\n",
       "Price_X+7th         1500.3\n",
       "Price_X+8th        1511.85\n",
       "Price_X+9th        1503.15\n",
       "Price_X+10th        1559.2\n",
       "Price_X+11th        1574.2\n",
       "Price_X+12th        1571.8\n",
       "Price_X+13th       1563.05\n",
       "Price_X+14th        1580.8\n",
       "Price_X+15th        1560.4\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.iloc[0,days_shape*days_shape:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe494b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e795cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ea8a02f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ea8a02f",
    "outputId": "cb7e946a-c9e5-43a3-bde8-2f89e78a9f60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3328\n",
       "1    2886\n",
       "Name: result, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = df5.copy()\n",
    "#df6 = df6.assign(result = lambda x: (((x['Close'] - x['Xth'])/x['Xth'])*100)>reward)\n",
    "df6['result'] = 0\n",
    "#print(df6['result'])\n",
    "for i in range(df6.shape[0]):\n",
    "    arr = np.array(df6.iloc[i,days_shape*days_shape+3:-1])\n",
    "    #print(arr)\n",
    "    max_arr = np.max(arr)\n",
    "    min_arr = np.min(arr)\n",
    "    #print(max_arr,min_arr)\n",
    "    if ((max_arr - df6.iloc[i,days_shape*days_shape])/df6.iloc[i,days_shape*days_shape]*100) >= reward:\n",
    "        df6.at[i,'result'] = 1\n",
    "        #print((max_arr - df6.iloc[i,days_shape*days_shape])/df6.iloc[i,days_shape*days_shape]*100, i)\n",
    "    #if ((min_arr - df6.iloc[i,days_shape*days_shape])/df6.iloc[i,days_shape*days_shape]*100) <= risk: \n",
    "        #df6.at[i,'result'] = -1\n",
    "    \n",
    "    \n",
    "df6['result'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2052721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 6214 entries, 0 to 6213\n",
      "Series name: result\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "6214 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 226.1 KB\n"
     ]
    }
   ],
   "source": [
    "df6['result'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4561cab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['result'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d220015a",
   "metadata": {
    "id": "d220015a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_X+7th</th>\n",
       "      <th>Price_X+8th</th>\n",
       "      <th>Price_X+9th</th>\n",
       "      <th>Price_X+10th</th>\n",
       "      <th>Price_X+11th</th>\n",
       "      <th>Price_X+12th</th>\n",
       "      <th>Price_X+13th</th>\n",
       "      <th>Price_X+14th</th>\n",
       "      <th>Price_X+15th</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631889</td>\n",
       "      <td>0.796883</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>2.713614</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>3.205083</td>\n",
       "      <td>2.604788</td>\n",
       "      <td>2.144913</td>\n",
       "      <td>1.351541</td>\n",
       "      <td>1.548129</td>\n",
       "      <td>...</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>1560.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166043</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.094962</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.589557</td>\n",
       "      <td>1.985445</td>\n",
       "      <td>1.522645</td>\n",
       "      <td>0.724228</td>\n",
       "      <td>0.922066</td>\n",
       "      <td>1.275348</td>\n",
       "      <td>...</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1580.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.649032</td>\n",
       "      <td>1.932128</td>\n",
       "      <td>1.649032</td>\n",
       "      <td>2.427545</td>\n",
       "      <td>1.822428</td>\n",
       "      <td>1.358859</td>\n",
       "      <td>0.559114</td>\n",
       "      <td>0.757281</td>\n",
       "      <td>1.111150</td>\n",
       "      <td>3.634240</td>\n",
       "      <td>...</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1563.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.295038</td>\n",
       "      <td>-1.108193</td>\n",
       "      <td>-0.906703</td>\n",
       "      <td>-0.546900</td>\n",
       "      <td>2.018494</td>\n",
       "      <td>2.993560</td>\n",
       "      <td>...</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1571.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.288673</td>\n",
       "      <td>0.505178</td>\n",
       "      <td>-0.111861</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-1.400065</td>\n",
       "      <td>-1.197994</td>\n",
       "      <td>-0.837152</td>\n",
       "      <td>1.735648</td>\n",
       "      <td>2.713528</td>\n",
       "      <td>2.248042</td>\n",
       "      <td>...</td>\n",
       "      <td>1473.90</td>\n",
       "      <td>1480.60</td>\n",
       "      <td>1495.30</td>\n",
       "      <td>1503.30</td>\n",
       "      <td>1500.30</td>\n",
       "      <td>1511.85</td>\n",
       "      <td>1503.15</td>\n",
       "      <td>1559.20</td>\n",
       "      <td>1574.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6209</th>\n",
       "      <td>-0.311174</td>\n",
       "      <td>-0.353607</td>\n",
       "      <td>1.485149</td>\n",
       "      <td>1.357850</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>0.282885</td>\n",
       "      <td>-0.424328</td>\n",
       "      <td>-0.063649</td>\n",
       "      <td>-0.424328</td>\n",
       "      <td>-0.424328</td>\n",
       "      <td>...</td>\n",
       "      <td>695.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>706.20</td>\n",
       "      <td>708.90</td>\n",
       "      <td>703.00</td>\n",
       "      <td>691.70</td>\n",
       "      <td>695.25</td>\n",
       "      <td>698.25</td>\n",
       "      <td>700.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6210</th>\n",
       "      <td>-0.042301</td>\n",
       "      <td>1.790750</td>\n",
       "      <td>1.663847</td>\n",
       "      <td>0.592217</td>\n",
       "      <td>0.592217</td>\n",
       "      <td>-0.112803</td>\n",
       "      <td>0.246757</td>\n",
       "      <td>-0.112803</td>\n",
       "      <td>-0.112803</td>\n",
       "      <td>0.317259</td>\n",
       "      <td>...</td>\n",
       "      <td>693.75</td>\n",
       "      <td>695.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>706.20</td>\n",
       "      <td>708.90</td>\n",
       "      <td>703.00</td>\n",
       "      <td>691.70</td>\n",
       "      <td>695.25</td>\n",
       "      <td>698.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>1.832276</td>\n",
       "      <td>1.705426</td>\n",
       "      <td>0.634249</td>\n",
       "      <td>0.634249</td>\n",
       "      <td>-0.070472</td>\n",
       "      <td>0.288936</td>\n",
       "      <td>-0.070472</td>\n",
       "      <td>-0.070472</td>\n",
       "      <td>0.359408</td>\n",
       "      <td>-0.084567</td>\n",
       "      <td>...</td>\n",
       "      <td>698.00</td>\n",
       "      <td>693.75</td>\n",
       "      <td>695.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>706.20</td>\n",
       "      <td>708.90</td>\n",
       "      <td>703.00</td>\n",
       "      <td>691.70</td>\n",
       "      <td>695.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6212</th>\n",
       "      <td>-0.129218</td>\n",
       "      <td>-1.220388</td>\n",
       "      <td>-1.220388</td>\n",
       "      <td>-1.938263</td>\n",
       "      <td>-1.572146</td>\n",
       "      <td>-1.938263</td>\n",
       "      <td>-1.938263</td>\n",
       "      <td>-1.500359</td>\n",
       "      <td>-1.952620</td>\n",
       "      <td>-1.335248</td>\n",
       "      <td>...</td>\n",
       "      <td>700.00</td>\n",
       "      <td>698.00</td>\n",
       "      <td>693.75</td>\n",
       "      <td>695.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>706.20</td>\n",
       "      <td>708.90</td>\n",
       "      <td>703.00</td>\n",
       "      <td>691.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>-1.089762</td>\n",
       "      <td>-1.089762</td>\n",
       "      <td>-1.806711</td>\n",
       "      <td>-1.441067</td>\n",
       "      <td>-1.806711</td>\n",
       "      <td>-1.806711</td>\n",
       "      <td>-1.369372</td>\n",
       "      <td>-1.821050</td>\n",
       "      <td>-1.204474</td>\n",
       "      <td>-0.953542</td>\n",
       "      <td>...</td>\n",
       "      <td>702.80</td>\n",
       "      <td>700.00</td>\n",
       "      <td>698.00</td>\n",
       "      <td>693.75</td>\n",
       "      <td>695.00</td>\n",
       "      <td>710.00</td>\n",
       "      <td>706.20</td>\n",
       "      <td>708.90</td>\n",
       "      <td>703.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6214 rows Ã— 3619 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.631889  0.796883  2.432774  2.713614  2.432774  3.205083  2.604788   \n",
       "1     0.166043  1.812337  2.094962  1.812337  2.589557  1.985445  1.522645   \n",
       "2     1.649032  1.932128  1.649032  2.427545  1.822428  1.358859  0.559114   \n",
       "3     0.287842  0.000000  0.791566  0.176303 -0.295038 -1.108193 -0.906703   \n",
       "4    -0.288673  0.505178 -0.111861 -0.584563 -1.400065 -1.197994 -0.837152   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "6209 -0.311174 -0.353607  1.485149  1.357850  0.282885  0.282885 -0.424328   \n",
       "6210 -0.042301  1.790750  1.663847  0.592217  0.592217 -0.112803  0.246757   \n",
       "6211  1.832276  1.705426  0.634249  0.634249 -0.070472  0.288936 -0.070472   \n",
       "6212 -0.129218 -1.220388 -1.220388 -1.938263 -1.572146 -1.938263 -1.938263   \n",
       "6213 -1.089762 -1.089762 -1.806711 -1.441067 -1.806711 -1.806711 -1.369372   \n",
       "\n",
       "             7         8         9  ...  Price_X+7th  Price_X+8th  \\\n",
       "0     2.144913  1.351541  1.548129  ...      1500.30      1511.85   \n",
       "1     0.724228  0.922066  1.275348  ...      1503.30      1500.30   \n",
       "2     0.757281  1.111150  3.634240  ...      1495.30      1503.30   \n",
       "3    -0.546900  2.018494  2.993560  ...      1480.60      1495.30   \n",
       "4     1.735648  2.713528  2.248042  ...      1473.90      1480.60   \n",
       "...        ...       ...       ...  ...          ...          ...   \n",
       "6209 -0.063649 -0.424328 -0.424328  ...       695.00       710.00   \n",
       "6210 -0.112803 -0.112803  0.317259  ...       693.75       695.00   \n",
       "6211 -0.070472  0.359408 -0.084567  ...       698.00       693.75   \n",
       "6212 -1.500359 -1.952620 -1.335248  ...       700.00       698.00   \n",
       "6213 -1.821050 -1.204474 -0.953542  ...       702.80       700.00   \n",
       "\n",
       "      Price_X+9th  Price_X+10th  Price_X+11th  Price_X+12th  Price_X+13th  \\\n",
       "0         1503.15       1559.20       1574.20       1571.80       1563.05   \n",
       "1         1511.85       1503.15       1559.20       1574.20       1571.80   \n",
       "2         1500.30       1511.85       1503.15       1559.20       1574.20   \n",
       "3         1503.30       1500.30       1511.85       1503.15       1559.20   \n",
       "4         1495.30       1503.30       1500.30       1511.85       1503.15   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "6209       706.20        708.90        703.00        691.70        695.25   \n",
       "6210       710.00        706.20        708.90        703.00        691.70   \n",
       "6211       695.00        710.00        706.20        708.90        703.00   \n",
       "6212       693.75        695.00        710.00        706.20        708.90   \n",
       "6213       698.00        693.75        695.00        710.00        706.20   \n",
       "\n",
       "      Price_X+14th  Price_X+15th  result  \n",
       "0          1580.80       1560.40       1  \n",
       "1          1563.05       1580.80       1  \n",
       "2          1571.80       1563.05       1  \n",
       "3          1574.20       1571.80       1  \n",
       "4          1559.20       1574.20       1  \n",
       "...            ...           ...     ...  \n",
       "6209        698.25        700.00       0  \n",
       "6210        695.25        698.25       0  \n",
       "6211        691.70        695.25       0  \n",
       "6212        703.00        691.70       0  \n",
       "6213        708.90        703.00       0  \n",
       "\n",
       "[6214 rows x 3619 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e326d2d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "e326d2d9",
    "outputId": "0bf59cc3-5a3a-4ab8-a839-fba1cd654cc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3590</th>\n",
       "      <th>3591</th>\n",
       "      <th>3592</th>\n",
       "      <th>3593</th>\n",
       "      <th>3594</th>\n",
       "      <th>3595</th>\n",
       "      <th>3596</th>\n",
       "      <th>3597</th>\n",
       "      <th>3598</th>\n",
       "      <th>3599</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631889</td>\n",
       "      <td>0.796883</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>2.713614</td>\n",
       "      <td>2.432774</td>\n",
       "      <td>3.205083</td>\n",
       "      <td>2.604788</td>\n",
       "      <td>2.144913</td>\n",
       "      <td>1.351541</td>\n",
       "      <td>1.548129</td>\n",
       "      <td>...</td>\n",
       "      <td>9.059170</td>\n",
       "      <td>9.786522</td>\n",
       "      <td>10.095647</td>\n",
       "      <td>8.859148</td>\n",
       "      <td>11.226679</td>\n",
       "      <td>14.368840</td>\n",
       "      <td>13.459650</td>\n",
       "      <td>15.685347</td>\n",
       "      <td>15.212569</td>\n",
       "      <td>16.019929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166043</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.094962</td>\n",
       "      <td>1.812337</td>\n",
       "      <td>2.589557</td>\n",
       "      <td>1.985445</td>\n",
       "      <td>1.522645</td>\n",
       "      <td>0.724228</td>\n",
       "      <td>0.922066</td>\n",
       "      <td>1.275348</td>\n",
       "      <td>...</td>\n",
       "      <td>9.344736</td>\n",
       "      <td>9.655374</td>\n",
       "      <td>8.412820</td>\n",
       "      <td>10.791945</td>\n",
       "      <td>13.949494</td>\n",
       "      <td>13.035851</td>\n",
       "      <td>15.272448</td>\n",
       "      <td>14.797354</td>\n",
       "      <td>15.608669</td>\n",
       "      <td>14.881409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.649032</td>\n",
       "      <td>1.932128</td>\n",
       "      <td>1.649032</td>\n",
       "      <td>2.427545</td>\n",
       "      <td>1.822428</td>\n",
       "      <td>1.358859</td>\n",
       "      <td>0.559114</td>\n",
       "      <td>0.757281</td>\n",
       "      <td>1.111150</td>\n",
       "      <td>3.634240</td>\n",
       "      <td>...</td>\n",
       "      <td>8.137936</td>\n",
       "      <td>6.874512</td>\n",
       "      <td>9.293597</td>\n",
       "      <td>12.504180</td>\n",
       "      <td>11.575192</td>\n",
       "      <td>13.849355</td>\n",
       "      <td>13.366281</td>\n",
       "      <td>14.191223</td>\n",
       "      <td>13.451748</td>\n",
       "      <td>13.552079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791566</td>\n",
       "      <td>0.176303</td>\n",
       "      <td>-0.295038</td>\n",
       "      <td>-1.108193</td>\n",
       "      <td>-0.906703</td>\n",
       "      <td>-0.546900</td>\n",
       "      <td>2.018494</td>\n",
       "      <td>2.993560</td>\n",
       "      <td>...</td>\n",
       "      <td>6.191278</td>\n",
       "      <td>8.628112</td>\n",
       "      <td>11.862250</td>\n",
       "      <td>10.926446</td>\n",
       "      <td>13.217294</td>\n",
       "      <td>12.730676</td>\n",
       "      <td>13.561669</td>\n",
       "      <td>12.816770</td>\n",
       "      <td>12.917836</td>\n",
       "      <td>12.577204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.288673</td>\n",
       "      <td>0.505178</td>\n",
       "      <td>-0.111861</td>\n",
       "      <td>-0.584563</td>\n",
       "      <td>-1.400065</td>\n",
       "      <td>-1.197994</td>\n",
       "      <td>-0.837152</td>\n",
       "      <td>1.735648</td>\n",
       "      <td>2.713528</td>\n",
       "      <td>2.248042</td>\n",
       "      <td>...</td>\n",
       "      <td>7.306144</td>\n",
       "      <td>10.587074</td>\n",
       "      <td>9.637731</td>\n",
       "      <td>11.961722</td>\n",
       "      <td>11.468064</td>\n",
       "      <td>12.311081</td>\n",
       "      <td>11.555404</td>\n",
       "      <td>11.657933</td>\n",
       "      <td>11.312372</td>\n",
       "      <td>10.746563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.631889  0.796883  2.432774  2.713614  2.432774  3.205083  2.604788   \n",
       "1  0.166043  1.812337  2.094962  1.812337  2.589557  1.985445  1.522645   \n",
       "2  1.649032  1.932128  1.649032  2.427545  1.822428  1.358859  0.559114   \n",
       "3  0.287842  0.000000  0.791566  0.176303 -0.295038 -1.108193 -0.906703   \n",
       "4 -0.288673  0.505178 -0.111861 -0.584563 -1.400065 -1.197994 -0.837152   \n",
       "\n",
       "       7         8         9     ...      3590       3591       3592  \\\n",
       "0  2.144913  1.351541  1.548129  ...  9.059170   9.786522  10.095647   \n",
       "1  0.724228  0.922066  1.275348  ...  9.344736   9.655374   8.412820   \n",
       "2  0.757281  1.111150  3.634240  ...  8.137936   6.874512   9.293597   \n",
       "3 -0.546900  2.018494  2.993560  ...  6.191278   8.628112  11.862250   \n",
       "4  1.735648  2.713528  2.248042  ...  7.306144  10.587074   9.637731   \n",
       "\n",
       "        3593       3594       3595       3596       3597       3598       3599  \n",
       "0   8.859148  11.226679  14.368840  13.459650  15.685347  15.212569  16.019929  \n",
       "1  10.791945  13.949494  13.035851  15.272448  14.797354  15.608669  14.881409  \n",
       "2  12.504180  11.575192  13.849355  13.366281  14.191223  13.451748  13.552079  \n",
       "3  10.926446  13.217294  12.730676  13.561669  12.816770  12.917836  12.577204  \n",
       "4  11.961722  11.468064  12.311081  11.555404  11.657933  11.312372  10.746563  \n",
       "\n",
       "[5 rows x 3600 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = df6.iloc[:,0:3600]\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0069ff48",
   "metadata": {
    "id": "0069ff48"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bee952a",
   "metadata": {
    "id": "3bee952a"
   },
   "outputs": [],
   "source": [
    "X = df7\n",
    "y = df6[\"result\"]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98a31311",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98a31311",
    "outputId": "3f34572d-8d8a-491d-e6ae-0947ffc38a0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971, 3600)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "338f935c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "338f935c",
    "outputId": "188b129a-7c02-4f86-c67a-ebabbd806989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1243, 3600)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed063454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "LTzxOZpGcERP",
   "metadata": {
    "id": "LTzxOZpGcERP"
   },
   "outputs": [],
   "source": [
    "aess = X_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "222e8eff",
   "metadata": {
    "id": "222e8eff"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train1 = np.asarray(X_train).astype(np.float32)\n",
    "X_test1 = np.asarray(X_test).astype(np.float32)\n",
    "y_train1 = np.asarray(y_train).astype(np.float32)\n",
    "y_test1 = np.asarray(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71dfd58f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71dfd58f",
    "outputId": "f00ac31b-a311-468b-80bf-069d97e12fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "156/156 [==============================] - 33s 197ms/step - loss: 0.7527 - accuracy: 0.5220\n",
      "Epoch 2/500\n",
      "156/156 [==============================] - 30s 195ms/step - loss: 0.6967 - accuracy: 0.5381\n",
      "Epoch 3/500\n",
      "156/156 [==============================] - 30s 195ms/step - loss: 0.6779 - accuracy: 0.5631\n",
      "Epoch 4/500\n",
      "156/156 [==============================] - 30s 194ms/step - loss: 0.6777 - accuracy: 0.5655\n",
      "Epoch 5/500\n",
      "156/156 [==============================] - 29s 186ms/step - loss: 0.6754 - accuracy: 0.5667\n",
      "Epoch 6/500\n",
      "156/156 [==============================] - 28s 181ms/step - loss: 0.6685 - accuracy: 0.5733\n",
      "Epoch 7/500\n",
      "156/156 [==============================] - 28s 181ms/step - loss: 0.6736 - accuracy: 0.5677\n",
      "Epoch 8/500\n",
      "156/156 [==============================] - 29s 184ms/step - loss: 0.6641 - accuracy: 0.5737\n",
      "Epoch 9/500\n",
      "156/156 [==============================] - 30s 194ms/step - loss: 0.6569 - accuracy: 0.5934\n",
      "Epoch 10/500\n",
      "156/156 [==============================] - 30s 193ms/step - loss: 0.6535 - accuracy: 0.5979\n",
      "Epoch 11/500\n",
      "156/156 [==============================] - 30s 193ms/step - loss: 0.6496 - accuracy: 0.5985\n",
      "Epoch 12/500\n",
      "156/156 [==============================] - 30s 193ms/step - loss: 0.6510 - accuracy: 0.5977\n",
      "Epoch 13/500\n",
      "156/156 [==============================] - 30s 190ms/step - loss: 0.6492 - accuracy: 0.5940\n",
      "Epoch 14/500\n",
      "156/156 [==============================] - 30s 191ms/step - loss: 0.6375 - accuracy: 0.6119\n",
      "Epoch 15/500\n",
      "156/156 [==============================] - 29s 189ms/step - loss: 0.6325 - accuracy: 0.6091\n",
      "Epoch 16/500\n",
      "156/156 [==============================] - 30s 192ms/step - loss: 0.6311 - accuracy: 0.6132\n",
      "Epoch 17/500\n",
      "156/156 [==============================] - 30s 193ms/step - loss: 0.6237 - accuracy: 0.6170\n",
      "Epoch 18/500\n",
      "156/156 [==============================] - 21s 137ms/step - loss: 0.6210 - accuracy: 0.6216\n",
      "Epoch 19/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.6121 - accuracy: 0.6301\n",
      "Epoch 20/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.6061 - accuracy: 0.6301\n",
      "Epoch 21/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.6055 - accuracy: 0.6373\n",
      "Epoch 22/500\n",
      "156/156 [==============================] - 20s 129ms/step - loss: 0.6073 - accuracy: 0.6409\n",
      "Epoch 23/500\n",
      "156/156 [==============================] - 20s 131ms/step - loss: 0.5971 - accuracy: 0.6465\n",
      "Epoch 24/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5868 - accuracy: 0.6518\n",
      "Epoch 25/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.5862 - accuracy: 0.6614\n",
      "Epoch 26/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5817 - accuracy: 0.6598\n",
      "Epoch 27/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.5721 - accuracy: 0.6719\n",
      "Epoch 28/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.5715 - accuracy: 0.6705\n",
      "Epoch 29/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.5790 - accuracy: 0.6600\n",
      "Epoch 30/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5581 - accuracy: 0.6791\n",
      "Epoch 31/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.5549 - accuracy: 0.6791\n",
      "Epoch 32/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.5528 - accuracy: 0.6862\n",
      "Epoch 33/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.5487 - accuracy: 0.6948\n",
      "Epoch 34/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.5387 - accuracy: 0.6938\n",
      "Epoch 35/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.5501 - accuracy: 0.6812\n",
      "Epoch 36/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5404 - accuracy: 0.6848\n",
      "Epoch 37/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5297 - accuracy: 0.6952\n",
      "Epoch 38/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5213 - accuracy: 0.7069\n",
      "Epoch 39/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5117 - accuracy: 0.7141\n",
      "Epoch 40/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5077 - accuracy: 0.7220\n",
      "Epoch 41/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.4974 - accuracy: 0.7282\n",
      "Epoch 42/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.5026 - accuracy: 0.7202\n",
      "Epoch 43/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5071 - accuracy: 0.7162\n",
      "Epoch 44/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.5156 - accuracy: 0.7172\n",
      "Epoch 45/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.4913 - accuracy: 0.7278\n",
      "Epoch 46/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.4885 - accuracy: 0.7353\n",
      "Epoch 47/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.4894 - accuracy: 0.7401\n",
      "Epoch 48/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.4906 - accuracy: 0.7373\n",
      "Epoch 49/500\n",
      "156/156 [==============================] - 18s 115ms/step - loss: 0.4708 - accuracy: 0.7409\n",
      "Epoch 50/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.4869 - accuracy: 0.7423\n",
      "Epoch 51/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.4621 - accuracy: 0.7558\n",
      "Epoch 52/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4630 - accuracy: 0.7536\n",
      "Epoch 53/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4592 - accuracy: 0.7556\n",
      "Epoch 54/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4532 - accuracy: 0.7612\n",
      "Epoch 55/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.4649 - accuracy: 0.7485\n",
      "Epoch 56/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4477 - accuracy: 0.7604\n",
      "Epoch 57/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4456 - accuracy: 0.7648\n",
      "Epoch 58/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.4435 - accuracy: 0.7707\n",
      "Epoch 59/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4269 - accuracy: 0.7707\n",
      "Epoch 60/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.4432 - accuracy: 0.7685\n",
      "Epoch 61/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.4278 - accuracy: 0.7783\n",
      "Epoch 62/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4342 - accuracy: 0.7721\n",
      "Epoch 63/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.4283 - accuracy: 0.7817\n",
      "Epoch 64/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.4245 - accuracy: 0.7753\n",
      "Epoch 65/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.4231 - accuracy: 0.7831\n",
      "Epoch 66/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.4091 - accuracy: 0.7870\n",
      "Epoch 67/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.4174 - accuracy: 0.7843\n",
      "Epoch 68/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.4231 - accuracy: 0.7833\n",
      "Epoch 69/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.4039 - accuracy: 0.7926\n",
      "Epoch 70/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.4185 - accuracy: 0.7803\n",
      "Epoch 71/500\n",
      "156/156 [==============================] - 21s 136ms/step - loss: 0.3982 - accuracy: 0.7938\n",
      "Epoch 72/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.4301 - accuracy: 0.7711\n",
      "Epoch 73/500\n",
      "156/156 [==============================] - 20s 128ms/step - loss: 0.4078 - accuracy: 0.7888\n",
      "Epoch 74/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.4088 - accuracy: 0.7864\n",
      "Epoch 75/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.4048 - accuracy: 0.7934\n",
      "Epoch 76/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.4159 - accuracy: 0.7894\n",
      "Epoch 77/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.3983 - accuracy: 0.8004\n",
      "Epoch 78/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.4061 - accuracy: 0.7950\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3894 - accuracy: 0.8039\n",
      "Epoch 80/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3909 - accuracy: 0.7986\n",
      "Epoch 81/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3853 - accuracy: 0.8057\n",
      "Epoch 82/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.4020 - accuracy: 0.7984\n",
      "Epoch 83/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.3760 - accuracy: 0.8087\n",
      "Epoch 84/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.3800 - accuracy: 0.8033\n",
      "Epoch 85/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.3977 - accuracy: 0.7926\n",
      "Epoch 86/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.3760 - accuracy: 0.8137\n",
      "Epoch 87/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3908 - accuracy: 0.7968\n",
      "Epoch 88/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3773 - accuracy: 0.8069\n",
      "Epoch 89/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3677 - accuracy: 0.8192\n",
      "Epoch 90/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3747 - accuracy: 0.8087\n",
      "Epoch 91/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3808 - accuracy: 0.8077\n",
      "Epoch 92/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3648 - accuracy: 0.8129\n",
      "Epoch 93/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3654 - accuracy: 0.8177\n",
      "Epoch 94/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3727 - accuracy: 0.8097\n",
      "Epoch 95/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3601 - accuracy: 0.8246\n",
      "Epoch 96/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3595 - accuracy: 0.8254\n",
      "Epoch 97/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3756 - accuracy: 0.8129\n",
      "Epoch 98/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3690 - accuracy: 0.8123\n",
      "Epoch 99/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3648 - accuracy: 0.8177\n",
      "Epoch 100/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3746 - accuracy: 0.8121\n",
      "Epoch 101/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3588 - accuracy: 0.8192\n",
      "Epoch 102/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3502 - accuracy: 0.8260\n",
      "Epoch 103/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3430 - accuracy: 0.8310\n",
      "Epoch 104/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3523 - accuracy: 0.8250\n",
      "Epoch 105/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3576 - accuracy: 0.8230\n",
      "Epoch 106/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3525 - accuracy: 0.8302\n",
      "Epoch 107/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3505 - accuracy: 0.8264\n",
      "Epoch 108/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3515 - accuracy: 0.8280\n",
      "Epoch 109/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3414 - accuracy: 0.8316\n",
      "Epoch 110/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3562 - accuracy: 0.8316\n",
      "Epoch 111/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3399 - accuracy: 0.8348\n",
      "Epoch 112/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3358 - accuracy: 0.8393\n",
      "Epoch 113/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3440 - accuracy: 0.8258\n",
      "Epoch 114/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.3510 - accuracy: 0.8240\n",
      "Epoch 115/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3315 - accuracy: 0.8387\n",
      "Epoch 116/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.3390 - accuracy: 0.8354\n",
      "Epoch 117/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3335 - accuracy: 0.8358\n",
      "Epoch 118/500\n",
      "156/156 [==============================] - 21s 135ms/step - loss: 0.3475 - accuracy: 0.8288\n",
      "Epoch 119/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.3243 - accuracy: 0.8395\n",
      "Epoch 120/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3316 - accuracy: 0.8461\n",
      "Epoch 121/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3267 - accuracy: 0.8465\n",
      "Epoch 122/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3204 - accuracy: 0.8443\n",
      "Epoch 123/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3285 - accuracy: 0.8360\n",
      "Epoch 124/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.3225 - accuracy: 0.8445\n",
      "Epoch 125/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.3174 - accuracy: 0.8546\n",
      "Epoch 126/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3333 - accuracy: 0.8391\n",
      "Epoch 127/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3220 - accuracy: 0.8453\n",
      "Epoch 128/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3219 - accuracy: 0.8457\n",
      "Epoch 129/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3165 - accuracy: 0.8459\n",
      "Epoch 130/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3135 - accuracy: 0.8471\n",
      "Epoch 131/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2993 - accuracy: 0.8531\n",
      "Epoch 132/500\n",
      "156/156 [==============================] - 20s 128ms/step - loss: 0.3206 - accuracy: 0.8481\n",
      "Epoch 133/500\n",
      "156/156 [==============================] - 20s 128ms/step - loss: 0.3121 - accuracy: 0.8499\n",
      "Epoch 134/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.3052 - accuracy: 0.8576\n",
      "Epoch 135/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.3196 - accuracy: 0.8481\n",
      "Epoch 136/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.3013 - accuracy: 0.8586\n",
      "Epoch 137/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.3159 - accuracy: 0.8453\n",
      "Epoch 138/500\n",
      "156/156 [==============================] - 17s 109ms/step - loss: 0.3173 - accuracy: 0.8485\n",
      "Epoch 139/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.3018 - accuracy: 0.8554\n",
      "Epoch 140/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2995 - accuracy: 0.8533\n",
      "Epoch 141/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2956 - accuracy: 0.8546\n",
      "Epoch 142/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2937 - accuracy: 0.8614\n",
      "Epoch 143/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2962 - accuracy: 0.8574\n",
      "Epoch 144/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.3000 - accuracy: 0.8536\n",
      "Epoch 145/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.3022 - accuracy: 0.8580\n",
      "Epoch 146/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.3069 - accuracy: 0.8505\n",
      "Epoch 147/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.3263 - accuracy: 0.8473\n",
      "Epoch 148/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2966 - accuracy: 0.8608\n",
      "Epoch 149/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2911 - accuracy: 0.8632\n",
      "Epoch 150/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2952 - accuracy: 0.8610\n",
      "Epoch 151/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.3072 - accuracy: 0.8628\n",
      "Epoch 152/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2987 - accuracy: 0.8646\n",
      "Epoch 153/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2833 - accuracy: 0.8721\n",
      "Epoch 154/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2968 - accuracy: 0.8642\n",
      "Epoch 155/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2789 - accuracy: 0.8692\n",
      "Epoch 156/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 16s 105ms/step - loss: 0.3010 - accuracy: 0.8540\n",
      "Epoch 157/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2856 - accuracy: 0.8672\n",
      "Epoch 158/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2873 - accuracy: 0.8694\n",
      "Epoch 159/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2736 - accuracy: 0.8704\n",
      "Epoch 160/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.3095 - accuracy: 0.8582\n",
      "Epoch 161/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2948 - accuracy: 0.8618\n",
      "Epoch 162/500\n",
      "156/156 [==============================] - 17s 108ms/step - loss: 0.2722 - accuracy: 0.8725\n",
      "Epoch 163/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2882 - accuracy: 0.8622\n",
      "Epoch 164/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2812 - accuracy: 0.8670\n",
      "Epoch 165/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2718 - accuracy: 0.8715\n",
      "Epoch 166/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2802 - accuracy: 0.8731\n",
      "Epoch 167/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2907 - accuracy: 0.8632\n",
      "Epoch 168/500\n",
      "156/156 [==============================] - 17s 111ms/step - loss: 0.2739 - accuracy: 0.8698\n",
      "Epoch 169/500\n",
      "156/156 [==============================] - 17s 111ms/step - loss: 0.3023 - accuracy: 0.8568\n",
      "Epoch 170/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2924 - accuracy: 0.8638\n",
      "Epoch 171/500\n",
      "156/156 [==============================] - 17s 108ms/step - loss: 0.2877 - accuracy: 0.8602\n",
      "Epoch 172/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2822 - accuracy: 0.8686\n",
      "Epoch 173/500\n",
      "156/156 [==============================] - 17s 109ms/step - loss: 0.2772 - accuracy: 0.8743\n",
      "Epoch 174/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2759 - accuracy: 0.8751\n",
      "Epoch 175/500\n",
      "156/156 [==============================] - 17s 108ms/step - loss: 0.2706 - accuracy: 0.8727\n",
      "Epoch 176/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2616 - accuracy: 0.8815\n",
      "Epoch 177/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2723 - accuracy: 0.8721\n",
      "Epoch 178/500\n",
      "156/156 [==============================] - 17s 110ms/step - loss: 0.2863 - accuracy: 0.8678\n",
      "Epoch 179/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2747 - accuracy: 0.8680\n",
      "Epoch 180/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2819 - accuracy: 0.8636\n",
      "Epoch 181/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2697 - accuracy: 0.8739\n",
      "Epoch 182/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2796 - accuracy: 0.8733\n",
      "Epoch 183/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2758 - accuracy: 0.8721\n",
      "Epoch 184/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2873 - accuracy: 0.8628\n",
      "Epoch 185/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2704 - accuracy: 0.8775\n",
      "Epoch 186/500\n",
      "156/156 [==============================] - 17s 109ms/step - loss: 0.2768 - accuracy: 0.8733\n",
      "Epoch 187/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2731 - accuracy: 0.8741\n",
      "Epoch 188/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2744 - accuracy: 0.8727\n",
      "Epoch 189/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2591 - accuracy: 0.8779\n",
      "Epoch 190/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2553 - accuracy: 0.8801\n",
      "Epoch 191/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2661 - accuracy: 0.8771\n",
      "Epoch 192/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2552 - accuracy: 0.8845\n",
      "Epoch 193/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2539 - accuracy: 0.8855\n",
      "Epoch 194/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2678 - accuracy: 0.8791\n",
      "Epoch 195/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2635 - accuracy: 0.8763\n",
      "Epoch 196/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2769 - accuracy: 0.8731\n",
      "Epoch 197/500\n",
      "156/156 [==============================] - 19s 121ms/step - loss: 0.2727 - accuracy: 0.8753\n",
      "Epoch 198/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2855 - accuracy: 0.8729\n",
      "Epoch 199/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2710 - accuracy: 0.8702\n",
      "Epoch 200/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2631 - accuracy: 0.8777\n",
      "Epoch 201/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2728 - accuracy: 0.8688\n",
      "Epoch 202/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2699 - accuracy: 0.8759\n",
      "Epoch 203/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2651 - accuracy: 0.8757\n",
      "Epoch 204/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2653 - accuracy: 0.8769\n",
      "Epoch 205/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2629 - accuracy: 0.8739\n",
      "Epoch 206/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2519 - accuracy: 0.8841\n",
      "Epoch 207/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2572 - accuracy: 0.8829\n",
      "Epoch 208/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2543 - accuracy: 0.8829\n",
      "Epoch 209/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2492 - accuracy: 0.8847\n",
      "Epoch 210/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2679 - accuracy: 0.8745\n",
      "Epoch 211/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2567 - accuracy: 0.8789\n",
      "Epoch 212/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2507 - accuracy: 0.8831\n",
      "Epoch 213/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2585 - accuracy: 0.8821\n",
      "Epoch 214/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2468 - accuracy: 0.8863\n",
      "Epoch 215/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2534 - accuracy: 0.8851\n",
      "Epoch 216/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2589 - accuracy: 0.8777\n",
      "Epoch 217/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2506 - accuracy: 0.8829\n",
      "Epoch 218/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.2535 - accuracy: 0.8777\n",
      "Epoch 219/500\n",
      "156/156 [==============================] - 21s 136ms/step - loss: 0.2455 - accuracy: 0.8869\n",
      "Epoch 220/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2587 - accuracy: 0.8817\n",
      "Epoch 221/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2563 - accuracy: 0.8787\n",
      "Epoch 222/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2487 - accuracy: 0.8823\n",
      "Epoch 223/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.2541 - accuracy: 0.8821\n",
      "Epoch 224/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2551 - accuracy: 0.8799\n",
      "Epoch 225/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.2504 - accuracy: 0.8797\n",
      "Epoch 226/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2518 - accuracy: 0.8861\n",
      "Epoch 227/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.2494 - accuracy: 0.8863\n",
      "Epoch 228/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.2385 - accuracy: 0.8910\n",
      "Epoch 229/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2451 - accuracy: 0.8819\n",
      "Epoch 230/500\n",
      "156/156 [==============================] - 17s 109ms/step - loss: 0.2506 - accuracy: 0.8898\n",
      "Epoch 231/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2415 - accuracy: 0.8855\n",
      "Epoch 232/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2476 - accuracy: 0.8873\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2432 - accuracy: 0.8900\n",
      "Epoch 234/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2518 - accuracy: 0.8859\n",
      "Epoch 235/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2456 - accuracy: 0.8861\n",
      "Epoch 236/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2313 - accuracy: 0.8924\n",
      "Epoch 237/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2482 - accuracy: 0.8916\n",
      "Epoch 238/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2395 - accuracy: 0.8908\n",
      "Epoch 239/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2470 - accuracy: 0.8827\n",
      "Epoch 240/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2322 - accuracy: 0.8952\n",
      "Epoch 241/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2349 - accuracy: 0.8942\n",
      "Epoch 242/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2275 - accuracy: 0.8932\n",
      "Epoch 243/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2378 - accuracy: 0.8984\n",
      "Epoch 244/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2286 - accuracy: 0.8916\n",
      "Epoch 245/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2463 - accuracy: 0.8861\n",
      "Epoch 246/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2281 - accuracy: 0.8966\n",
      "Epoch 247/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2509 - accuracy: 0.8837\n",
      "Epoch 248/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2574 - accuracy: 0.8841\n",
      "Epoch 249/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2519 - accuracy: 0.8817\n",
      "Epoch 250/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2410 - accuracy: 0.8884\n",
      "Epoch 251/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2483 - accuracy: 0.8865\n",
      "Epoch 252/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2326 - accuracy: 0.8956\n",
      "Epoch 253/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2631 - accuracy: 0.8833\n",
      "Epoch 254/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2390 - accuracy: 0.8896\n",
      "Epoch 255/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2263 - accuracy: 0.8994\n",
      "Epoch 256/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2328 - accuracy: 0.8936\n",
      "Epoch 257/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2290 - accuracy: 0.8976\n",
      "Epoch 258/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2305 - accuracy: 0.8910\n",
      "Epoch 259/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2324 - accuracy: 0.8954\n",
      "Epoch 260/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2394 - accuracy: 0.8884\n",
      "Epoch 261/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2279 - accuracy: 0.8952\n",
      "Epoch 262/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2423 - accuracy: 0.8865\n",
      "Epoch 263/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2498 - accuracy: 0.8849\n",
      "Epoch 264/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2386 - accuracy: 0.8898\n",
      "Epoch 265/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2256 - accuracy: 0.8956\n",
      "Epoch 266/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2347 - accuracy: 0.8930\n",
      "Epoch 267/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2229 - accuracy: 0.9002\n",
      "Epoch 268/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2290 - accuracy: 0.8950\n",
      "Epoch 269/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2424 - accuracy: 0.8918\n",
      "Epoch 270/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.2192 - accuracy: 0.9010\n",
      "Epoch 271/500\n",
      "156/156 [==============================] - 17s 108ms/step - loss: 0.2278 - accuracy: 0.9010\n",
      "Epoch 272/500\n",
      "156/156 [==============================] - 17s 110ms/step - loss: 0.2416 - accuracy: 0.8944\n",
      "Epoch 273/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2302 - accuracy: 0.8972\n",
      "Epoch 274/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2303 - accuracy: 0.8974\n",
      "Epoch 275/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2344 - accuracy: 0.8954\n",
      "Epoch 276/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2143 - accuracy: 0.9048\n",
      "Epoch 277/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.2313 - accuracy: 0.8914\n",
      "Epoch 278/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.2263 - accuracy: 0.8984\n",
      "Epoch 279/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2220 - accuracy: 0.8960\n",
      "Epoch 280/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2333 - accuracy: 0.8952\n",
      "Epoch 281/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.2218 - accuracy: 0.9008\n",
      "Epoch 282/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2629 - accuracy: 0.8853\n",
      "Epoch 283/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2297 - accuracy: 0.9010\n",
      "Epoch 284/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2296 - accuracy: 0.8992\n",
      "Epoch 285/500\n",
      "156/156 [==============================] - 17s 110ms/step - loss: 0.2252 - accuracy: 0.9022\n",
      "Epoch 286/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2340 - accuracy: 0.8930\n",
      "Epoch 287/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2049 - accuracy: 0.9073\n",
      "Epoch 288/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2359 - accuracy: 0.8930\n",
      "Epoch 289/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2257 - accuracy: 0.8990\n",
      "Epoch 290/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2327 - accuracy: 0.8992\n",
      "Epoch 291/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2158 - accuracy: 0.9081\n",
      "Epoch 292/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2183 - accuracy: 0.9016\n",
      "Epoch 293/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2153 - accuracy: 0.9065\n",
      "Epoch 294/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2219 - accuracy: 0.8982\n",
      "Epoch 295/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2039 - accuracy: 0.9097\n",
      "Epoch 296/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1939 - accuracy: 0.9145\n",
      "Epoch 297/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2207 - accuracy: 0.9065\n",
      "Epoch 298/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2113 - accuracy: 0.9022\n",
      "Epoch 299/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2155 - accuracy: 0.9022\n",
      "Epoch 300/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2122 - accuracy: 0.9061\n",
      "Epoch 301/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2052 - accuracy: 0.9101\n",
      "Epoch 302/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2156 - accuracy: 0.9028\n",
      "Epoch 303/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2218 - accuracy: 0.9004\n",
      "Epoch 304/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2238 - accuracy: 0.8990\n",
      "Epoch 305/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2332 - accuracy: 0.8944\n",
      "Epoch 306/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.2197 - accuracy: 0.9042\n",
      "Epoch 307/500\n",
      "156/156 [==============================] - 17s 110ms/step - loss: 0.2021 - accuracy: 0.9127\n",
      "Epoch 308/500\n",
      "156/156 [==============================] - 19s 120ms/step - loss: 0.2129 - accuracy: 0.9055\n",
      "Epoch 309/500\n",
      "156/156 [==============================] - 21s 133ms/step - loss: 0.2207 - accuracy: 0.8994\n",
      "Epoch 310/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 20s 127ms/step - loss: 0.2053 - accuracy: 0.9059\n",
      "Epoch 311/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2165 - accuracy: 0.9040\n",
      "Epoch 312/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.2038 - accuracy: 0.9089\n",
      "Epoch 313/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.2149 - accuracy: 0.9022\n",
      "Epoch 314/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.2044 - accuracy: 0.9097\n",
      "Epoch 315/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1995 - accuracy: 0.9095\n",
      "Epoch 316/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2060 - accuracy: 0.9067\n",
      "Epoch 317/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2203 - accuracy: 0.9012\n",
      "Epoch 318/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2138 - accuracy: 0.9030\n",
      "Epoch 319/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2179 - accuracy: 0.8982\n",
      "Epoch 320/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2172 - accuracy: 0.9006\n",
      "Epoch 321/500\n",
      "156/156 [==============================] - 20s 126ms/step - loss: 0.2161 - accuracy: 0.9024\n",
      "Epoch 322/500\n",
      "156/156 [==============================] - 18s 118ms/step - loss: 0.1972 - accuracy: 0.9147\n",
      "Epoch 323/500\n",
      "156/156 [==============================] - 18s 116ms/step - loss: 0.2132 - accuracy: 0.9042\n",
      "Epoch 324/500\n",
      "156/156 [==============================] - 19s 119ms/step - loss: 0.1926 - accuracy: 0.9167\n",
      "Epoch 325/500\n",
      "156/156 [==============================] - 18s 119ms/step - loss: 0.2143 - accuracy: 0.9059\n",
      "Epoch 326/500\n",
      "156/156 [==============================] - 19s 120ms/step - loss: 0.2171 - accuracy: 0.9022\n",
      "Epoch 327/500\n",
      "156/156 [==============================] - 18s 115ms/step - loss: 0.2085 - accuracy: 0.9048\n",
      "Epoch 328/500\n",
      "156/156 [==============================] - 17s 109ms/step - loss: 0.2162 - accuracy: 0.9057\n",
      "Epoch 329/500\n",
      "156/156 [==============================] - 17s 109ms/step - loss: 0.1906 - accuracy: 0.9193\n",
      "Epoch 330/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2036 - accuracy: 0.9139\n",
      "Epoch 331/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2120 - accuracy: 0.9105\n",
      "Epoch 332/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2034 - accuracy: 0.9093\n",
      "Epoch 333/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2113 - accuracy: 0.9085\n",
      "Epoch 334/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2062 - accuracy: 0.9111\n",
      "Epoch 335/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1939 - accuracy: 0.9161\n",
      "Epoch 336/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1887 - accuracy: 0.9157\n",
      "Epoch 337/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2024 - accuracy: 0.9097\n",
      "Epoch 338/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1980 - accuracy: 0.9143\n",
      "Epoch 339/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1952 - accuracy: 0.9151\n",
      "Epoch 340/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2074 - accuracy: 0.9079\n",
      "Epoch 341/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.2181 - accuracy: 0.9008\n",
      "Epoch 342/500\n",
      "156/156 [==============================] - 19s 121ms/step - loss: 0.2059 - accuracy: 0.9071\n",
      "Epoch 343/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1910 - accuracy: 0.9165\n",
      "Epoch 344/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1991 - accuracy: 0.9117\n",
      "Epoch 345/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1904 - accuracy: 0.9135\n",
      "Epoch 346/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1951 - accuracy: 0.9119\n",
      "Epoch 347/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.1978 - accuracy: 0.9155\n",
      "Epoch 348/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.2025 - accuracy: 0.9105\n",
      "Epoch 349/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1974 - accuracy: 0.9121\n",
      "Epoch 350/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1921 - accuracy: 0.9147\n",
      "Epoch 351/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.2010 - accuracy: 0.9127\n",
      "Epoch 352/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2123 - accuracy: 0.9121\n",
      "Epoch 353/500\n",
      "156/156 [==============================] - 19s 121ms/step - loss: 0.2007 - accuracy: 0.9117\n",
      "Epoch 354/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1950 - accuracy: 0.9161\n",
      "Epoch 355/500\n",
      "156/156 [==============================] - 19s 121ms/step - loss: 0.1894 - accuracy: 0.9177\n",
      "Epoch 356/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1870 - accuracy: 0.9179\n",
      "Epoch 357/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1919 - accuracy: 0.9137\n",
      "Epoch 358/500\n",
      "156/156 [==============================] - 19s 121ms/step - loss: 0.1962 - accuracy: 0.9205\n",
      "Epoch 359/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1897 - accuracy: 0.9157\n",
      "Epoch 360/500\n",
      "156/156 [==============================] - 19s 121ms/step - loss: 0.2145 - accuracy: 0.9032\n",
      "Epoch 361/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1905 - accuracy: 0.9163\n",
      "Epoch 362/500\n",
      "156/156 [==============================] - 18s 117ms/step - loss: 0.2074 - accuracy: 0.9107\n",
      "Epoch 363/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2022 - accuracy: 0.9113\n",
      "Epoch 364/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1976 - accuracy: 0.9119\n",
      "Epoch 365/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1862 - accuracy: 0.9171\n",
      "Epoch 366/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1910 - accuracy: 0.9151\n",
      "Epoch 367/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1848 - accuracy: 0.9157\n",
      "Epoch 368/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1872 - accuracy: 0.9177\n",
      "Epoch 369/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1825 - accuracy: 0.9199\n",
      "Epoch 370/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.2155 - accuracy: 0.9048\n",
      "Epoch 371/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1982 - accuracy: 0.9143\n",
      "Epoch 372/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2194 - accuracy: 0.9069\n",
      "Epoch 373/500\n",
      "156/156 [==============================] - 18s 113ms/step - loss: 0.1893 - accuracy: 0.9159\n",
      "Epoch 374/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1910 - accuracy: 0.9185\n",
      "Epoch 375/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1900 - accuracy: 0.9155\n",
      "Epoch 376/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.2077 - accuracy: 0.9133\n",
      "Epoch 377/500\n",
      "156/156 [==============================] - 16s 106ms/step - loss: 0.2215 - accuracy: 0.8998\n",
      "Epoch 378/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2073 - accuracy: 0.9050\n",
      "Epoch 379/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.2213 - accuracy: 0.9026\n",
      "Epoch 380/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1808 - accuracy: 0.9213\n",
      "Epoch 381/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.1895 - accuracy: 0.9167\n",
      "Epoch 382/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.1935 - accuracy: 0.9167\n",
      "Epoch 383/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.2075 - accuracy: 0.9101\n",
      "Epoch 384/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.1899 - accuracy: 0.9213\n",
      "Epoch 385/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1896 - accuracy: 0.9167\n",
      "Epoch 386/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1861 - accuracy: 0.9189\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1822 - accuracy: 0.9203\n",
      "Epoch 388/500\n",
      "156/156 [==============================] - 17s 107ms/step - loss: 0.1812 - accuracy: 0.9175\n",
      "Epoch 389/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.1722 - accuracy: 0.9260\n",
      "Epoch 390/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.1990 - accuracy: 0.9143\n",
      "Epoch 391/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.1852 - accuracy: 0.9211\n",
      "Epoch 392/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1767 - accuracy: 0.9262\n",
      "Epoch 393/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1938 - accuracy: 0.9177\n",
      "Epoch 394/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1960 - accuracy: 0.9141\n",
      "Epoch 395/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1782 - accuracy: 0.9256\n",
      "Epoch 396/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1837 - accuracy: 0.9131\n",
      "Epoch 397/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1810 - accuracy: 0.9221\n",
      "Epoch 398/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1793 - accuracy: 0.9230\n",
      "Epoch 399/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1698 - accuracy: 0.9240\n",
      "Epoch 400/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1691 - accuracy: 0.9248\n",
      "Epoch 401/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1810 - accuracy: 0.9209\n",
      "Epoch 402/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1804 - accuracy: 0.9236\n",
      "Epoch 403/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1905 - accuracy: 0.9163\n",
      "Epoch 404/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.2208 - accuracy: 0.9018\n",
      "Epoch 405/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1787 - accuracy: 0.9260\n",
      "Epoch 406/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1634 - accuracy: 0.9306\n",
      "Epoch 407/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1731 - accuracy: 0.9260\n",
      "Epoch 408/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1717 - accuracy: 0.9252\n",
      "Epoch 409/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1739 - accuracy: 0.9242\n",
      "Epoch 410/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1697 - accuracy: 0.9260\n",
      "Epoch 411/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1613 - accuracy: 0.9330\n",
      "Epoch 412/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1709 - accuracy: 0.9290\n",
      "Epoch 413/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1844 - accuracy: 0.9189\n",
      "Epoch 414/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1783 - accuracy: 0.9217\n",
      "Epoch 415/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1826 - accuracy: 0.9230\n",
      "Epoch 416/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1912 - accuracy: 0.9226\n",
      "Epoch 417/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1784 - accuracy: 0.9226\n",
      "Epoch 418/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1800 - accuracy: 0.9238\n",
      "Epoch 419/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1712 - accuracy: 0.9254\n",
      "Epoch 420/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1681 - accuracy: 0.9252\n",
      "Epoch 421/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1827 - accuracy: 0.9248\n",
      "Epoch 422/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1830 - accuracy: 0.9193\n",
      "Epoch 423/500\n",
      "156/156 [==============================] - 21s 135ms/step - loss: 0.1834 - accuracy: 0.9203\n",
      "Epoch 424/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1803 - accuracy: 0.9232\n",
      "Epoch 425/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1854 - accuracy: 0.9195\n",
      "Epoch 426/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1792 - accuracy: 0.9215\n",
      "Epoch 427/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1880 - accuracy: 0.9171\n",
      "Epoch 428/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1679 - accuracy: 0.9213\n",
      "Epoch 429/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1842 - accuracy: 0.9183\n",
      "Epoch 430/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1700 - accuracy: 0.9250\n",
      "Epoch 431/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1765 - accuracy: 0.9260\n",
      "Epoch 432/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1892 - accuracy: 0.9175\n",
      "Epoch 433/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1682 - accuracy: 0.9234\n",
      "Epoch 434/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1871 - accuracy: 0.9193\n",
      "Epoch 435/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1778 - accuracy: 0.9189\n",
      "Epoch 436/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1739 - accuracy: 0.9223\n",
      "Epoch 437/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1621 - accuracy: 0.9296\n",
      "Epoch 438/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1636 - accuracy: 0.9298\n",
      "Epoch 439/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1548 - accuracy: 0.9344\n",
      "Epoch 440/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1804 - accuracy: 0.9268\n",
      "Epoch 441/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1694 - accuracy: 0.9268\n",
      "Epoch 442/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1587 - accuracy: 0.9316\n",
      "Epoch 443/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.1723 - accuracy: 0.9242\n",
      "Epoch 444/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.1842 - accuracy: 0.9181\n",
      "Epoch 445/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1481 - accuracy: 0.9372\n",
      "Epoch 446/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1558 - accuracy: 0.9350\n",
      "Epoch 447/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1779 - accuracy: 0.9230\n",
      "Epoch 448/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1944 - accuracy: 0.9179\n",
      "Epoch 449/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1593 - accuracy: 0.9306\n",
      "Epoch 450/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1602 - accuracy: 0.9334\n",
      "Epoch 451/500\n",
      "156/156 [==============================] - 19s 121ms/step - loss: 0.1812 - accuracy: 0.9232\n",
      "Epoch 452/500\n",
      "156/156 [==============================] - 17s 108ms/step - loss: 0.1652 - accuracy: 0.9274\n",
      "Epoch 453/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.1691 - accuracy: 0.9302\n",
      "Epoch 454/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1887 - accuracy: 0.9211\n",
      "Epoch 455/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1644 - accuracy: 0.9280\n",
      "Epoch 456/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1731 - accuracy: 0.9276\n",
      "Epoch 457/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1962 - accuracy: 0.9155\n",
      "Epoch 458/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.1626 - accuracy: 0.9300\n",
      "Epoch 459/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1717 - accuracy: 0.9280\n",
      "Epoch 460/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.1843 - accuracy: 0.9179\n",
      "Epoch 461/500\n",
      "156/156 [==============================] - 17s 106ms/step - loss: 0.1686 - accuracy: 0.9306\n",
      "Epoch 462/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.1653 - accuracy: 0.9280\n",
      "Epoch 463/500\n",
      "156/156 [==============================] - 16s 105ms/step - loss: 0.1769 - accuracy: 0.9201\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1637 - accuracy: 0.9264\n",
      "Epoch 465/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1702 - accuracy: 0.9280\n",
      "Epoch 466/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1575 - accuracy: 0.9336\n",
      "Epoch 467/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1648 - accuracy: 0.9296\n",
      "Epoch 468/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1698 - accuracy: 0.9258\n",
      "Epoch 469/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1567 - accuracy: 0.9342\n",
      "Epoch 470/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1525 - accuracy: 0.9344\n",
      "Epoch 471/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1504 - accuracy: 0.9382\n",
      "Epoch 472/500\n",
      "156/156 [==============================] - 16s 104ms/step - loss: 0.1586 - accuracy: 0.9316\n",
      "Epoch 473/500\n",
      "156/156 [==============================] - 18s 113ms/step - loss: 0.1660 - accuracy: 0.9268\n",
      "Epoch 474/500\n",
      "156/156 [==============================] - 16s 103ms/step - loss: 0.1760 - accuracy: 0.9254\n",
      "Epoch 475/500\n",
      "156/156 [==============================] - 20s 127ms/step - loss: 0.1768 - accuracy: 0.9256\n",
      "Epoch 476/500\n",
      "156/156 [==============================] - 20s 125ms/step - loss: 0.1533 - accuracy: 0.9399\n",
      "Epoch 477/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1555 - accuracy: 0.9338\n",
      "Epoch 478/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1621 - accuracy: 0.9312\n",
      "Epoch 479/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1568 - accuracy: 0.9326\n",
      "Epoch 480/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1666 - accuracy: 0.9346\n",
      "Epoch 481/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1524 - accuracy: 0.9388\n",
      "Epoch 482/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1627 - accuracy: 0.9272\n",
      "Epoch 483/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1592 - accuracy: 0.9350\n",
      "Epoch 484/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1603 - accuracy: 0.9314\n",
      "Epoch 485/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1532 - accuracy: 0.9334\n",
      "Epoch 486/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1534 - accuracy: 0.9350\n",
      "Epoch 487/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1544 - accuracy: 0.9340\n",
      "Epoch 488/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1625 - accuracy: 0.9328\n",
      "Epoch 489/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1836 - accuracy: 0.9228\n",
      "Epoch 490/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1651 - accuracy: 0.9276\n",
      "Epoch 491/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1636 - accuracy: 0.9288\n",
      "Epoch 492/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1604 - accuracy: 0.9348\n",
      "Epoch 493/500\n",
      "156/156 [==============================] - 19s 124ms/step - loss: 0.1678 - accuracy: 0.9238\n",
      "Epoch 494/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1641 - accuracy: 0.9310\n",
      "Epoch 495/500\n",
      "156/156 [==============================] - 19s 125ms/step - loss: 0.1677 - accuracy: 0.9320\n",
      "Epoch 496/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1648 - accuracy: 0.9300\n",
      "Epoch 497/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1635 - accuracy: 0.9276\n",
      "Epoch 498/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1551 - accuracy: 0.9334\n",
      "Epoch 499/500\n",
      "156/156 [==============================] - 19s 123ms/step - loss: 0.1583 - accuracy: 0.9320\n",
      "Epoch 500/500\n",
      "156/156 [==============================] - 19s 122ms/step - loss: 0.1530 - accuracy: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1460ddf5c40>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#model = keras.Sequential([\n",
    "    #keras.layers.Dense(aess, input_shape=(aess,), activation='sigmoid'),\n",
    "    #keras.layers.Dense(2000, activation='relu'),\n",
    "    #keras.layers.Dense(65, activation='relu'),\n",
    "    #keras.layers.Dense(30, activation='relu'),\n",
    "    #keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train1, y_train1, epochs=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000072b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=(3600,)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "JnEWToraP2KN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JnEWToraP2KN",
    "outputId": "c3755ada-40d6-4d9f-d434-0112bb3f7ef9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 19ms/step - loss: 0.6328 - accuracy: 0.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6327843070030212, 0.8286404013633728]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "kQTxKoplQpru",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQTxKoplQpru",
    "outputId": "81c4c0fb-83c0-4245-d07e-1a642154489d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.6549668e-03],\n",
       "       [9.6774256e-01],\n",
       "       [7.1356954e-17],\n",
       "       [9.3528181e-01],\n",
       "       [9.4684714e-01]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecc160f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1243"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dTNySgZmQiJn",
   "metadata": {
    "id": "dTNySgZmQiJn"
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element >= 0.5:\n",
    "        y_pred.append(1)\n",
    "    #if element < 0.4 and element >=-0.4:\n",
    "        #y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "_Pv0vQW_QboG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Pv0vQW_QboG",
    "outputId": "b0e60373-32fa-43b8-d28c-a5b6b5692042"
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix , classification_report\n",
    "\n",
    "#print(classification_report(y_test1,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "KdNpNDi1QweS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "id": "KdNpNDi1QweS",
    "outputId": "1532d126-8738-43bd-e0c3-cc0c6b096b70",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import seaborn as sn\n",
    "#cm = tf.math.confusion_matrix(labels=y_test1,predictions=y_pred)\n",
    "\n",
    "#plt.figure(figsize = (10,7))\n",
    "#sn.heatmap(cm, annot=True, fmt='d')\n",
    "#plt.xlabel('Predicted')\n",
    "#plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c45bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee1ccdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(model, 'model33.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7df5933c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create confusion matrix\n",
    "cm = confusion_matrix(y_test1, y_pred)\n",
    "\n",
    "# create heatmap using seaborn\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "\n",
    "# set labels for the plot\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66f32eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a8d2f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.8721 - accuracy: 0.5619 - val_loss: 0.8052 - val_accuracy: 0.6050\n",
      "Epoch 2/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.7494 - accuracy: 0.5894 - val_loss: 0.6775 - val_accuracy: 0.6082\n",
      "Epoch 3/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.6899 - accuracy: 0.6315 - val_loss: 0.6667 - val_accuracy: 0.6219\n",
      "Epoch 4/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.6578 - accuracy: 0.6540 - val_loss: 0.7548 - val_accuracy: 0.6010\n",
      "Epoch 5/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.6193 - accuracy: 0.6673 - val_loss: 0.6898 - val_accuracy: 0.6380\n",
      "Epoch 6/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.6136 - accuracy: 0.6872 - val_loss: 0.7133 - val_accuracy: 0.6291\n",
      "Epoch 7/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.5835 - accuracy: 0.6970 - val_loss: 0.6736 - val_accuracy: 0.6436\n",
      "Epoch 8/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.5914 - accuracy: 0.6972 - val_loss: 0.6101 - val_accuracy: 0.6710\n",
      "Epoch 9/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.5603 - accuracy: 0.7228 - val_loss: 0.5972 - val_accuracy: 0.7176\n",
      "Epoch 10/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.5507 - accuracy: 0.7310 - val_loss: 0.7736 - val_accuracy: 0.6074\n",
      "Epoch 11/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.5566 - accuracy: 0.7256 - val_loss: 0.6796 - val_accuracy: 0.6557\n",
      "Epoch 12/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.5197 - accuracy: 0.7409 - val_loss: 0.6057 - val_accuracy: 0.6927\n",
      "Epoch 13/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.5179 - accuracy: 0.7544 - val_loss: 0.6166 - val_accuracy: 0.6911\n",
      "Epoch 14/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.4896 - accuracy: 0.7592 - val_loss: 0.6605 - val_accuracy: 0.6991\n",
      "Epoch 15/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.4797 - accuracy: 0.7759 - val_loss: 0.6834 - val_accuracy: 0.6919\n",
      "Epoch 16/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.4762 - accuracy: 0.7737 - val_loss: 0.6826 - val_accuracy: 0.7136\n",
      "Epoch 17/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.4514 - accuracy: 0.7918 - val_loss: 0.6386 - val_accuracy: 0.7064\n",
      "Epoch 18/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.4621 - accuracy: 0.7811 - val_loss: 0.7497 - val_accuracy: 0.7031\n",
      "Epoch 19/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.4842 - accuracy: 0.7747 - val_loss: 0.6592 - val_accuracy: 0.7321\n",
      "Epoch 20/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.4073 - accuracy: 0.8103 - val_loss: 0.6065 - val_accuracy: 0.7313\n",
      "Epoch 21/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.4300 - accuracy: 0.8037 - val_loss: 0.5940 - val_accuracy: 0.7329\n",
      "Epoch 22/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.3996 - accuracy: 0.8192 - val_loss: 0.5926 - val_accuracy: 0.7377\n",
      "Epoch 23/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.3984 - accuracy: 0.8208 - val_loss: 0.6558 - val_accuracy: 0.7144\n",
      "Epoch 24/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.4176 - accuracy: 0.8087 - val_loss: 0.5996 - val_accuracy: 0.7377\n",
      "Epoch 25/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.3882 - accuracy: 0.8264 - val_loss: 0.6067 - val_accuracy: 0.7377\n",
      "Epoch 26/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.3815 - accuracy: 0.8292 - val_loss: 0.5842 - val_accuracy: 0.7401\n",
      "Epoch 27/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.3582 - accuracy: 0.8379 - val_loss: 0.6040 - val_accuracy: 0.7643\n",
      "Epoch 28/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.3609 - accuracy: 0.8383 - val_loss: 0.5996 - val_accuracy: 0.7586\n",
      "Epoch 29/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.8497 - val_loss: 0.6669 - val_accuracy: 0.7506\n",
      "Epoch 30/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.3095 - accuracy: 0.8628 - val_loss: 0.6423 - val_accuracy: 0.7538\n",
      "Epoch 31/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.2912 - accuracy: 0.8735 - val_loss: 0.6213 - val_accuracy: 0.7675\n",
      "Epoch 32/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.3168 - accuracy: 0.8622 - val_loss: 0.6901 - val_accuracy: 0.7442\n",
      "Epoch 33/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.3090 - accuracy: 0.8660 - val_loss: 0.6222 - val_accuracy: 0.7611\n",
      "Epoch 34/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.2846 - accuracy: 0.8789 - val_loss: 0.6834 - val_accuracy: 0.7554\n",
      "Epoch 35/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.2855 - accuracy: 0.8823 - val_loss: 0.6826 - val_accuracy: 0.7627\n",
      "Epoch 36/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.3054 - accuracy: 0.8646 - val_loss: 0.7840 - val_accuracy: 0.7490\n",
      "Epoch 37/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.3048 - accuracy: 0.8743 - val_loss: 0.7075 - val_accuracy: 0.7715\n",
      "Epoch 38/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.2544 - accuracy: 0.8898 - val_loss: 0.6399 - val_accuracy: 0.7844\n",
      "Epoch 39/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.2639 - accuracy: 0.8932 - val_loss: 0.7058 - val_accuracy: 0.7635\n",
      "Epoch 40/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.2630 - accuracy: 0.8892 - val_loss: 0.6538 - val_accuracy: 0.7772\n",
      "Epoch 41/50\n",
      "156/156 [==============================] - 1s 8ms/step - loss: 0.2463 - accuracy: 0.8976 - val_loss: 0.6907 - val_accuracy: 0.7554\n",
      "Epoch 42/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.3017 - accuracy: 0.8847 - val_loss: 0.7369 - val_accuracy: 0.7691\n",
      "Epoch 43/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.2581 - accuracy: 0.8906 - val_loss: 0.7042 - val_accuracy: 0.7868\n",
      "Epoch 44/50\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.2244 - accuracy: 0.9050 - val_loss: 0.6906 - val_accuracy: 0.7932\n",
      "Epoch 45/50\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.2544 - accuracy: 0.8956 - val_loss: 0.6916 - val_accuracy: 0.7973\n",
      "Epoch 46/50\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.2035 - accuracy: 0.9153 - val_loss: 0.7052 - val_accuracy: 0.7900\n",
      "Epoch 47/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.2607 - accuracy: 0.8964 - val_loss: 0.8502 - val_accuracy: 0.7442\n",
      "Epoch 48/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.1925 - accuracy: 0.9195 - val_loss: 0.7287 - val_accuracy: 0.7997\n",
      "Epoch 49/50\n",
      "156/156 [==============================] - 1s 9ms/step - loss: 0.2026 - accuracy: 0.9221 - val_loss: 0.8654 - val_accuracy: 0.7659\n",
      "Epoch 50/50\n",
      "156/156 [==============================] - 2s 10ms/step - loss: 0.1988 - accuracy: 0.9268 - val_loss: 0.7332 - val_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data to improve model performance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(128, activation='relu', input_shape=(3600,)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16b5c7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 3ms/step - loss: 0.7332 - accuracy: 0.7812\n",
      "Test accuracy: 0.7811746001243591\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ed21d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7923847 ],\n",
       "       [0.00396858],\n",
       "       [0.98048115],\n",
       "       [0.01476552],\n",
       "       [0.02700086]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp = model.predict(X_test)\n",
    "yp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "789030da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = []\n",
    "for element in yp:\n",
    "    if element >= 0.5:\n",
    "        y_pred1.append(1)\n",
    "    #if element < 0.4 and element >=-0.4:\n",
    "        #y_pred.append(0)\n",
    "    else:\n",
    "        y_pred1.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8242a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "\n",
    "# create heatmap using seaborn\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "\n",
    "\n",
    "# set labels for the plot\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
