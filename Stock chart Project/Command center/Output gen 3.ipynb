{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d412e46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>360ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3MINDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AIAENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>ZENSARTECH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>ZOMATO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>ZYDUSLIFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ZYDUSWELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ECLERX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0        360ONE\n",
       "1       3MINDIA\n",
       "2           ABB\n",
       "3           ACC\n",
       "4        AIAENG\n",
       "..          ...\n",
       "496  ZENSARTECH\n",
       "497      ZOMATO\n",
       "498   ZYDUSLIFE\n",
       "499   ZYDUSWELL\n",
       "500      ECLERX\n",
       "\n",
       "[501 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "nifty_500 = pd.read_csv('ind_nifty500list.csv')\n",
    "stocks = nifty_500['Symbol'].values.tolist()\n",
    "stocks = pd.DataFrame(stocks)\n",
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7136acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe66116c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "# Define the list of NSE companies to fetch data for\n",
    "nse_companies = stocks[0] +'.NS'\n",
    "\n",
    "# Set the start and end dates\n",
    "end_date = datetime.date.today()\n",
    "start_date = end_date - datetime.timedelta(days=60)\n",
    "\n",
    "# Create an empty dictionary to store the data for each company\n",
    "data = {}\n",
    "\n",
    "# Loop through the list of companies and fetch their data\n",
    "for company in nse_companies:\n",
    "    data[company] = yf.download(company, start=start_date, end=end_date)\n",
    "\n",
    "# Print the data for each company\n",
    "for company in data:\n",
    "    print(company)\n",
    "    print(data[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd758cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed042bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dump = pd.DataFrame(data['ABB.NS'])\n",
    "\n",
    "data_dump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3887d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['360ONE.NS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['360ONE.NS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a49e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_days = 15\n",
    "reward = 5\n",
    "risk =1\n",
    "days_shape = 60\n",
    "eps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab03630",
   "metadata": {},
   "outputs": [],
   "source": [
    "    model11 = joblib.load('model11.pkl')\n",
    "    model12 = joblib.load('model12.pkl')\n",
    "    model13 = joblib.load('model13.pkl')\n",
    "    model21 = joblib.load('model11.pkl')\n",
    "    model22 = joblib.load('model12.pkl')\n",
    "    model23 = joblib.load('model13.pkl')    \n",
    "    model31 = joblib.load('model11.pkl')\n",
    "    model32 = joblib.load('model12.pkl')\n",
    "    model33 = joblib.load('model13.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76bc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0 \n",
    "for company in nse_companies:\n",
    "    \n",
    "    print('Completed',count,'out of 500 steps')\n",
    "    count = count+1\n",
    "    \n",
    "    current_data = data[company]\n",
    "    print(current_data.shape) \n",
    "    current_data['Date'] = current_data.index\n",
    "    current_data = current_data.reset_index(drop=True)\n",
    "    current_data = current_data[['Date','Close']]\n",
    "\n",
    "    current_data_05 = current_data\n",
    "    current_data_10 = current_data\n",
    "    current_data_15 = current_data\n",
    "    \n",
    "    current_data_05['Xth'] = current_data['Close'].shift(-1* pred_days)\n",
    "    current_data_10['Xth_10'] = current_data['Close'].shift(-1* (pred_days+5))\n",
    "    current_data_15['Xth_15'] = current_data['Close'].shift(-1* (pred_days+10))\n",
    "                                                         \n",
    "                                                       \n",
    "    c1 = []\n",
    "    for i in range(1,days_shape):\n",
    "        current_data_05['temp'] = current_data_05['Xth'] - current_data_05['Xth'].shift(-1*i)\n",
    "        current_data_05['temp'] = current_data_05['temp']/current_data_05['Xth']*100\n",
    "        c1.append(current_data_05['temp'].to_numpy())\n",
    "        \n",
    "    c11 =[]    \n",
    "    for i in range(1,days_shape):\n",
    "        current_data_10['temp'] = current_data_10['Xth'] - current_data_10['Xth'].shift(-1*i)\n",
    "        current_data_10['temp'] = current_data_10['temp']/current_data_10['Xth']*100\n",
    "        c11.append(current_data_10['temp'].to_numpy())\n",
    "\n",
    "    c111 = []\n",
    "    for i in range(1,days_shape):\n",
    "        current_data_15['temp'] = current_data_15['Xth'] - current_data_15['Xth'].shift(-1*i)\n",
    "        current_data_15['temp'] = current_data_15['temp']/current_data_15['Xth']*100\n",
    "        c111.append(current_data_15['temp'].to_numpy())        \n",
    "        \n",
    "    current_data1 = pd.DataFrame(c1)\n",
    "    current_data2 = current_data1.transpose()    \n",
    "\n",
    "    current_data11 = pd.DataFrame(c11)\n",
    "    current_data22 = current_data11.transpose()      \n",
    "    \n",
    "    current_data111 = pd.DataFrame(c111)\n",
    "    current_data222 = current_data111.transpose()  \n",
    "    \n",
    "    c2 =current_data2.to_numpy()\n",
    "    c22 =current_data22.to_numpy()\n",
    "    c222 =current_data222.to_numpy()\n",
    "    \n",
    "    c3 =[]\n",
    "    c33 =[]\n",
    "    c333 =[]\n",
    "\n",
    "    for i in range(int(len(c2)-days_shape)):\n",
    "        c6 = np.concatenate((c2[i:i+days_shape]))\n",
    "        c3.append(c6)\n",
    "        \n",
    "    for i in range(int(len(c22)-days_shape)):\n",
    "        c66 = np.concatenate((c22[i:i+days_shape]))\n",
    "        c33.append(c66)\n",
    "        \n",
    "    for i in range(int(len(c222)-days_shape)):\n",
    "        c666 = np.concatenate((c222[i:i+days_shape]))\n",
    "        c333.append(c666)       \n",
    "        \n",
    "    aes = current_data.shape[0]\n",
    "    \n",
    "    df4 = pd.DataFrame(c3)\n",
    "    df4['Close'] = current_data_05.iloc[:aes]['Close']\n",
    "    df4['Xth'] = current_data_05.iloc[:aes]['Xth']\n",
    "    \n",
    "    df44 = pd.DataFrame(c33)\n",
    "    df44['Close'] = current_data_10.iloc[:aes]['Close']\n",
    "    df44['Xth_10'] = current_data_10.iloc[:aes]['Xth_10']\n",
    "    \n",
    "    df444 = pd.DataFrame(c333)\n",
    "    df444['Close'] = current_data_15.iloc[:aes]['Close']\n",
    "    df444['Xth_15'] = current_data_15.iloc[:aes]['Xth_15']    \n",
    "    \n",
    "    df5 = df4.dropna()\n",
    "    df55 = df44.dropna()\n",
    "    df555 = df444.dropna()\n",
    "    \n",
    "    df6 = df5\n",
    "    df6 = df6.assign(result5_w1 = lambda x: ((x['Close'] - x['Xth'])/x['Xth']*100)>5)\n",
    "    df6 = df6.assign(result10_w1 = lambda x: ((x['Close'] - x['Xth'])/x['Xth']*100)>10)\n",
    "    df6 = df6.assign(result15_w1 = lambda x: ((x['Close'] - x['Xth'])/x['Xth']*100)>15)\n",
    "\n",
    "    df66 = df55\n",
    "    df66 = df66.assign(result5_w2 = lambda x: ((x['Close'] - x['Xth_10'])/x['Xth_10']*100)>5)\n",
    "    df66 = df66.assign(result10_w2 = lambda x: ((x['Close'] - x['Xth_10'])/x['Xth_10']*100)>10)\n",
    "    df66 = df66.assign(result15_w2 = lambda x: ((x['Close'] - x['Xth_10'])/x['Xth_10']*100)>15)\n",
    "    \n",
    "    df666 = df555\n",
    "    df666 = df666.assign(result5_w3 = lambda x: ((x['Close'] - x['Xth_15'])/x['Xth_15']*100)>5)\n",
    "    df666 = df666.assign(result10_w3 = lambda x: ((x['Close'] - x['Xth_15'])/x['Xth_15']*100)>10)\n",
    "    df666 = df666.assign(result15_w3 = lambda x: ((x['Close'] - x['Xth_15'])/x['Xth_15']*100)>15)\n",
    "    \n",
    "    #print(df6['result'].value_counts())  \n",
    "    \n",
    "    for i in range(len(df6.result5_w1)):\n",
    "        if df6['result5_w1'][i] == False:\n",
    "            df6['result5_w1'][i] = 0\n",
    "        else:\n",
    "            df6['result5_w1'][i] = 1\n",
    "\n",
    "    for i in range(len(df6.result10_w1)):\n",
    "        if df6['result10_w1'][i] == False:\n",
    "            df6['result10_w1'][i] = 0\n",
    "        else:\n",
    "            df6['result10_w1'][i] = 1\n",
    "\n",
    "    for i in range(len(df6.result15_w1)):\n",
    "        if df6['result15_w1'][i] == False:\n",
    "            df6['result15_w1'][i] = 0\n",
    "        else:\n",
    "            df6['result15_w1'][i] = 1            \n",
    "\n",
    "  #############################################          \n",
    "    for i in range(len(df66.result5_w2)):\n",
    "        if df66['result5_w2'][i] == False:\n",
    "            df66['result5_w2'][i] = 0\n",
    "        else:\n",
    "            df66['result5_w2'][i] = 1\n",
    "\n",
    "    for i in range(len(df66.result10_w2)):\n",
    "        if df66['result10_w2'][i] == False:\n",
    "            df66['result10_w2'][i] = 0\n",
    "        else:\n",
    "            df66['result10_w2'][i] = 1\n",
    "\n",
    "    for i in range(len(df66.result15_w2)):\n",
    "        if df66['result15_w2'][i] == False:\n",
    "            df66['result15_w2'][i] = 0\n",
    "        else:\n",
    "            df66['result15_w2'][i] = 1            \n",
    "            \n",
    "########################################################\n",
    "    for i in range(len(df666.result5_w3)):\n",
    "        if df666['result5_w3'][i] == False:\n",
    "            df666['result5_w3'][i] = 0\n",
    "        else:\n",
    "            df666['result5_w3'][i] = 1\n",
    "\n",
    "    for i in range(len(df666.result10_w3)):\n",
    "        if df666['result10_w3'][i] == False:\n",
    "            df666['result10_w3'][i] = 0\n",
    "        else:\n",
    "            df666['result10_w3'][i] = 1\n",
    "\n",
    "    for i in range(len(df666.result15_w3)):\n",
    "        if df666['result15_w3'][i] == False:\n",
    "            df666['result15_w3'][i] = 0\n",
    "        else:\n",
    "            df666['result15_w3'][i] = 1            \n",
    "            \n",
    " ####################################################           \n",
    "            \n",
    "    df7 = df6.drop(['Close','Xth'],axis=1)     \n",
    "    df77 = df66.drop(['Close','Xth_10'],axis=1) \n",
    "    df777 = df666.drop(['Close','Xth_15'],axis=1) \n",
    "    \n",
    "    X1 = df7.drop(['result5_w1','result10_w1','result15_w1'],axis='columns')\n",
    "    X2 = df77.drop(['result5_w2','result10_w2','result15_w2'],axis='columns')\n",
    "    X3 = df777.drop(['result5_w3','result10_w3','result15_w3'],axis='columns')\n",
    "    \n",
    "    import numpy as np\n",
    "     \n",
    "    print('shape of X1 is',X1.shape)    \n",
    "    X_1 = np.asarray(X1).astype(np.float32)\n",
    "    X_2 = np.asarray(X2).astype(np.float32)\n",
    "    X_3 = np.asarray(X3).astype(np.float32)\n",
    "    \n",
    "    y11 = df7[\"result5_w1\"]\n",
    "    y12 = df7[\"result10_w1\"]\n",
    "    y13 = df7[\"result15_w1\"]\n",
    "    y21 = df77[\"result5_w2\"]\n",
    "    y22 = df77[\"result10_w2\"]\n",
    "    y23 = df77[\"result15_w2\"]\n",
    "    y31 = df777[\"result5_w3\"]\n",
    "    y32 = df777[\"result10_w3\"]\n",
    "    y33 = df777[\"result15_w3\"]  \n",
    "    \n",
    "    \n",
    "    yp11 = model11.predict(X_1)\n",
    "    yp12 = model12.predict(X_1)\n",
    "    yp13 = model13.predict(X_1)\n",
    "    yp21 = model21.predict(X_2)\n",
    "    yp22 = model22.predict(X_2)\n",
    "    yp23 = model23.predict(X_2)\n",
    "    yp31 = model31.predict(X_3)\n",
    "    yp32 = model32.predict(X_3)\n",
    "    yp33 = model33.predict(X_3)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
